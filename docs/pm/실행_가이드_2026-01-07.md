#    

****: 2026 1 7  
****: , PM  
****: /       

---

##    

```
  : 12   (4,887 )
  : 4   (626 )
 : 99.9%   

  : 4,325  (  )
```

****:  DB , **   !**

---

## 1.  

### 1.1  

```bash
# Conda  
conda activate ddoksori

# PostgreSQL  
docker ps | grep postgres

# DB  
cd /home/maroco/ddoksori_demo/backend
conda run -n ddoksori python -c "
import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()
conn = psycopg2.connect(
    host=os.getenv('DB_HOST', 'localhost'),
    port=os.getenv('DB_PORT', '5432'),
    database=os.getenv('DB_NAME', 'ddoksori'),
    user=os.getenv('DB_USER', 'postgres'),
    password=os.getenv('DB_PASSWORD', 'postgres')
)
print(' DB  ')
conn.close()
"
```

---

## 2.   

### 2.1   

****: `backend/scripts/data_loading/process_all_laws.py`

****:
```bash
cd /home/maroco/ddoksori_demo/backend/scripts
conda run -n ddoksori python backend/scripts/data_loading/process_all_laws.py
```

** **:
```
================================================================================
    
================================================================================
  : 11
  - Civil_Law_chunks.jsonl
  - Commercial_Law_chunks.jsonl
  - ...

 : Civil_Law_chunks.jsonl
   : 1069 
   : 1 , 1069 

...

 
  -  : 11
  -  : 11
  -  : 3,828
  - : 0

    !
```

** **:
```
      : law:civil_law_chunks ()
  ...
  -  : 0  ←    
```

** **:
```bash
cd /home/maroco/ddoksori_demo/backend
conda run -n ddoksori python -c "
import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()
conn = psycopg2.connect(
    host=os.getenv('DB_HOST', 'localhost'),
    port=os.getenv('DB_PORT', '5432'),
    database=os.getenv('DB_NAME', 'ddoksori'),
    user=os.getenv('DB_USER', 'postgres'),
    password=os.getenv('DB_PASSWORD', 'postgres')
)
cur = conn.cursor()
cur.execute(\"SELECT COUNT(*) FROM documents WHERE doc_type = 'law'\")
print(f'  : {cur.fetchone()[0]}')
cur.execute(\"\"\"
    SELECT COUNT(*) 
    FROM documents d 
    JOIN chunks c ON d.doc_id = c.doc_id 
    WHERE d.doc_type = 'law'
\"\"\")
print(f'  : {cur.fetchone()[0]}')
conn.close()
"
```

---

### 2.2   

****: `backend/scripts/data_loading/process_criteria_tables.py`

****:
```bash
cd /home/maroco/ddoksori_demo/backend/scripts
conda run -n ddoksori python backend/scripts/data_loading/process_criteria_tables.py
```

** **:
```
================================================================================
  (table 1/3/4)   
================================================================================
  :
   table1_item_chunks.jsonl
   table3_warranty_chunks.jsonl
   table4_lifespan_chunks.jsonl

 :   (table1_item_chunks.jsonl)
   387  
   : 1 , 387 

...

 
  -  : 3
  -  : 3
  -  : 487
  - : 0

    !
```

** **:
```bash
cd /home/maroco/ddoksori_demo/backend
conda run -n ddoksori python -c "
import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()
conn = psycopg2.connect(
    host=os.getenv('DB_HOST', 'localhost'),
    port=os.getenv('DB_PORT', '5432'),
    database=os.getenv('DB_NAME', 'ddoksori'),
    user=os.getenv('DB_USER', 'postgres'),
    password=os.getenv('DB_PASSWORD', 'postgres')
)
cur = conn.cursor()
cur.execute(\"SELECT doc_id, title FROM documents WHERE doc_type LIKE '%criteria%'\")
for doc_id, title in cur.fetchall():
    print(f'{doc_id}: {title}')
conn.close()
"
```

---

### 2.3   

****: `backend/scripts/utilities/update_metadata_keywords.py`

****:
```bash
cd /home/maroco/ddoksori_demo/backend/scripts
conda run -n ddoksori python backend/scripts/utilities/update_metadata_keywords.py
```

** **:
```
================================================================================
   
================================================================================
 DB  
 MetadataEnricher  

   ...
 11,985  

    ...
 ID                                                                     
--------------------------------------------------------------------------------
counsel_case:1000001                                         15            0.0%
counsel_case:1000002                                         15            0.0%
...

================================================================================
  
================================================================================
  -  : 11,985
  -  : 11,985
  - : 0
  -  : 0.2

  :
                                                    
--------------------------------------------------------------------------------
counsel_case                   11342      11342            100.0%
law                            12         12               100.0%
...

    !
```

** **:    (`metadata || new_metadata`)   

---

## 3.   :  

### 3.1    

```bash
cd /home/maroco/ddoksori_demo/backend
conda run -n ddoksori python -c "
import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()
conn = psycopg2.connect(
    host=os.getenv('DB_HOST', 'localhost'),
    port=os.getenv('DB_PORT', '5432'),
    database=os.getenv('DB_NAME', 'ddoksori'),
    user=os.getenv('DB_USER', 'postgres'),
    password=os.getenv('DB_PASSWORD', 'postgres')
)
cur = conn.cursor()

#    
cur.execute(\"\"\"
    SELECT 
        d.doc_type,
        COUNT(*) as total_chunks,
        COUNT(CASE WHEN c.embedding IS NULL THEN 1 END) as need_embedding
    FROM documents d
    JOIN chunks c ON d.doc_id = c.doc_id
    WHERE c.drop = FALSE
    GROUP BY d.doc_type
    ORDER BY need_embedding DESC
\"\"\")

print('  :')
print(f'{\" \":<30} {\" \":<10} {\" \":<10}')
print('-' * 60)
total_need = 0
for doc_type, total, need in cur.fetchall():
    if need > 0:
        print(f'{doc_type:<30} {total:<10} {need:<10}')
        total_need += need

print('-' * 60)
print(f'{\"\":<30} {\"-\":<10} {total_need:<10}')

conn.close()
"
```

** **:
```
  :
                                        
------------------------------------------------------------
law                            4887       3828      
criteria_item_list             387        387       
criteria_warranty              38         38        
criteria_lifespan              62         62        
------------------------------------------------------------
                            -          4325      
```

### 3.2    

    :
```bash
ls -la /home/maroco/ddoksori_demo/backend/scripts/*embed*.py
```

**  **:

```python
# backend/scripts/generate_embeddings_incremental.py
#!/usr/bin/env python3
"""
     

Usage:
    conda run -n ddoksori python generate_embeddings_incremental.py
"""

import sys
from pathlib import Path
import psycopg2
import os
from dotenv import load_dotenv
import torch
from transformers import AutoModel, AutoTokenizer
from tqdm import tqdm

#   
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

load_dotenv(project_root / '.env')


def get_embeddings(texts, model, tokenizer, device, batch_size=8):
    """  """
    embeddings = []
    
    for i in tqdm(range(0, len(texts), batch_size), desc=" "):
        batch = texts[i:i+batch_size]
        
        # 
        inputs = tokenizer(
            batch,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors='pt'
        ).to(device)
        
        #  
        with torch.no_grad():
            outputs = model(**inputs)
            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
        
        embeddings.extend(batch_embeddings)
    
    return embeddings


def main():
    print("=" * 80)
    print("   ( )")
    print("=" * 80)
    
    # DB 
    conn = psycopg2.connect(
        host=os.getenv('DB_HOST', 'localhost'),
        port=os.getenv('DB_PORT', '5432'),
        database=os.getenv('DB_NAME', 'ddoksori'),
        user=os.getenv('DB_USER', 'postgres'),
        password=os.getenv('DB_PASSWORD', 'postgres')
    )
    cur = conn.cursor()
    
    #    
    print("\n    ...")
    cur.execute("""
        SELECT chunk_id, content
        FROM chunks
        WHERE drop = FALSE AND embedding IS NULL
        ORDER BY chunk_id
    """)
    
    chunks = cur.fetchall()
    print(f" {len(chunks):,}  ")
    
    if len(chunks) == 0:
        print("   !")
        conn.close()
        return
    
    #  
    print("\n  ...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f": {device}")
    
    model_name = 'nlpai-lab/KURE-v1'
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name).to(device)
    model.eval()
    print("   ")
    
    #  
    print(f"\n  ... ( {len(chunks):,})")
    chunk_ids = [c[0] for c in chunks]
    contents = [c[1] for c in chunks]
    
    batch_size = 16 if device.type == 'cuda' else 8
    embeddings = get_embeddings(contents, model, tokenizer, device, batch_size)
    
    # DB 
    print("\nDB  ...")
    for chunk_id, embedding in tqdm(zip(chunk_ids, embeddings), total=len(chunk_ids), desc="DB "):
        cur.execute("""
            UPDATE chunks
            SET embedding = %s, updated_at = NOW()
            WHERE chunk_id = %s
        """, (embedding.tolist(), chunk_id))
        
        # 100 
        if (chunk_ids.index(chunk_id) + 1) % 100 == 0:
            conn.commit()
    
    #  
    conn.commit()
    
    # 
    print("\n ...")
    cur.execute("""
        SELECT COUNT(*) 
        FROM chunks 
        WHERE drop = FALSE AND embedding IS NULL
    """)
    remaining = cur.fetchone()[0]
    
    print("\n" + "=" * 80)
    print("  ")
    print("=" * 80)
    print(f"  -  : {len(embeddings):,}")
    print(f"  -  : {remaining:,}")
    print(f"  - : {(len(embeddings)/(len(embeddings)+remaining)*100):.1f}%")
    
    conn.close()


if __name__ == "__main__":
    main()
```

### 3.3   

```bash
cd /home/maroco/ddoksori_demo/backend/scripts

# GPU    
conda run -n ddoksori python -c "import torch; print(f'CUDA  : {torch.cuda.is_available()}')"

#    (  !)
conda run -n ddoksori python generate_embeddings_incremental.py
```

**  **:
- **GPU  **:  30-40 (4,325 )
- **CPU  **:  2-3

** ** ():
```bash
nohup conda run -n ddoksori python generate_embeddings_incremental.py > /tmp/embedding_generation.log 2>&1 &

#  
tail -f /tmp/embedding_generation.log
```

---

## 4.    ()

### 4.1 1:  

```bash
cd /home/maroco/ddoksori_demo/backend/scripts

# 1.  
conda run -n ddoksori python backend/scripts/data_loading/process_all_laws.py

# 2.  
conda run -n ddoksori python backend/scripts/data_loading/process_criteria_tables.py

# 3.  
conda run -n ddoksori python backend/scripts/utilities/update_metadata_keywords.py
```

** **:  10-15

### 4.2 2:  

```bash
cd /home/maroco/ddoksori_demo/backend/scripts

#   ()
nohup conda run -n ddoksori python generate_embeddings_incremental.py > /tmp/embedding_generation.log 2>&1 &

#   
tail -f /tmp/embedding_generation.log
```

** **: GPU   30-40

### 4.3 3: 

```bash
cd /home/maroco/ddoksori_demo/backend

#   
conda run -n ddoksori python -c "
import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()
conn = psycopg2.connect(
    host=os.getenv('DB_HOST', 'localhost'),
    port=os.getenv('DB_PORT', '5432'),
    database=os.getenv('DB_NAME', 'ddoksori'),
    user=os.getenv('DB_USER', 'postgres'),
    password=os.getenv('DB_PASSWORD', 'postgres')
)
cur = conn.cursor()

print('  ')
print('=' * 60)

#  
cur.execute('SELECT COUNT(*) FROM documents')
total_docs = cur.fetchone()[0]
cur.execute('SELECT COUNT(*) FROM chunks WHERE drop=FALSE')
total_chunks = cur.fetchone()[0]
cur.execute('SELECT COUNT(*) FROM chunks WHERE drop=FALSE AND embedding IS NOT NULL')
embedded_chunks = cur.fetchone()[0]

print(f' : {total_docs:,}')
print(f' : {total_chunks:,}')
print(f' : {embedded_chunks:,}')
print(f' : {embedded_chunks/total_chunks*100:.1f}%')

#  
cur.execute(\"\"\"
    SELECT COUNT(*) 
    FROM documents 
    WHERE metadata ? 'keywords'
\"\"\")
keyword_docs = cur.fetchone()[0]
print(f' : {keyword_docs}/{total_docs} ({keyword_docs/total_docs*100:.1f}%)')

conn.close()

print('=' * 60)
print('   !' if embedded_chunks == total_chunks else '    ')
"
```

---

## 5.  

### 5.1 "   " ( )

****:  DB   ( )

****:
```bash
cd /home/maroco/ddoksori_demo/backend/scripts
conda run -n ddoksori python backend/scripts/data_loading/process_all_laws.py
```

****:
```
      : law:civil_law_chunks ()
  ...
  -  : 0  ← !
```

****:   , ** ** !

### 5.2 "DB  "

****: PostgreSQL    

****:
```bash
# Docker PostgreSQL 
cd /home/maroco/ddoksori_demo
docker-compose up -d postgres

# 
docker ps | grep postgres
```

### 5.3 "  "

****: KURE-v1   

****:
```bash
conda run -n ddoksori python -c "
from transformers import AutoModel, AutoTokenizer

model_name = 'nlpai-lab/KURE-v1'
print('  ...')
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)
print('  ')
"
```

### 5.4 " "

****: GPU/CPU  

****:   
```python
# generate_embeddings_incremental.py
batch_size = 4  #  8 → 4 
```

---

## 6.  

### 6.1   

1. **  **
   ```bash
   cd /home/maroco/ddoksori_demo/backend/scripts
   conda run -n ddoksori python backend/scripts/evaluation/evaluate_hybrid_search.py
   ```

2. **RAG  **
   ```bash
   cd /home/maroco/ddoksori_demo/backend
   conda run -n ddoksori pytest tests/test_rag.py -v
   ```

3. **API  **
   ```bash
   cd /home/maroco/ddoksori_demo/backend
   conda run -n ddoksori uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

### 6.2  

4. **   **
   ```sql
   -- statute:001706 () 
   DELETE FROM documents WHERE doc_id = 'statute:001706';
   ```

5. **Golden Dataset **
   - table1       

---

## 7.  

### 7.1   

```bash
cd /home/maroco/ddoksori_demo/backend
conda run -n ddoksori python -c "
import psycopg2, os
from dotenv import load_dotenv
load_dotenv()
conn = psycopg2.connect(
    host=os.getenv('DB_HOST', 'localhost'),
    port=os.getenv('DB_PORT', '5432'),
    database=os.getenv('DB_NAME', 'ddoksori'),
    user=os.getenv('DB_USER', 'postgres'),
    password=os.getenv('DB_PASSWORD', 'postgres')
)
cur = conn.cursor()
cur.execute('SELECT COUNT(*) FROM documents')
docs = cur.fetchone()[0]
cur.execute('SELECT COUNT(*) FROM chunks WHERE drop=FALSE AND embedding IS NULL')
need_emb = cur.fetchone()[0]
print(f': {docs:,}')
print(f' : {need_emb:,} ')
print(' ' if need_emb == 0 else '   ')
conn.close()
"
```

### 7.2  

```
backend/scripts/
 data_loading/
    process_all_laws.py          ←   
    process_criteria_tables.py   ←   
 utilities/
    update_metadata_keywords.py  ←  
 generate_embeddings_incremental.py  ←   ( )
```

---

****: AI Assistant  
** **: 2026 1 7  
** **: [`____2026-01-07.md`](./____2026-01-07.md)
