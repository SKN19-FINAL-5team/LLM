# chunk_index ê²€í†  ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2026-01-06  
**ëª©ì **: ì„ë² ë”© ì¤‘ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ chunk_index ì¼ê´€ì„± ê²€í†   
**ì‹¬ê°ë„**: ğŸ”´ **HIGH** - ì„ë² ë”© ì¤‘ë‹¨ ì‹œ ì¬ì‹œì‘ ë¹„ìš© ë§¤ìš° í¼

---

## ğŸš¨ í•µì‹¬ ë°œê²¬

### âš ï¸ ë¬¸ì œ: chunk_index ì¸ë±ì‹± ë°©ì‹ì´ íŒŒì¼ë§ˆë‹¤ ë‹¤ë¦„

| íŒŒì¼ | chunk_index í•„ë“œ | ì‹œì‘ ê°’ | ìƒíƒœ |
|-----|-----------------|--------|------|
| **compensation_case** | âœ… ìˆìŒ | **0** | âœ… 0-based (ì •ìƒ) |
| **table2 (criteria)** | âŒ ì—†ìŒ (row_idxë§Œ ì¡´ì¬) | **1** | âš ï¸ 1-based |
| **kca_final** | âŒ ì—†ìŒ (case_indexëŠ” ë¬¸ì„œ ë²ˆí˜¸) | **1** | âš ï¸ 1-based |
| **ecmc** | âŒ ì—†ìŒ (seqëŠ” 1ë¶€í„° ì‹œì‘) | **1** | âš ï¸ 1-based |
| **law** | âŒ ì—†ìŒ (unit_idë§Œ ì¡´ì¬) | N/A | âš ï¸ ì¸ë±ìŠ¤ ì—†ìŒ |

---

## ğŸ“Š ìƒì„¸ ë¶„ì„ ê²°ê³¼

### 1. compensation_case (í”¼í•´êµ¬ì œì‚¬ë¡€) âœ…

```json
{
  "chunk_index": 0,      // âœ… 0-based
  "chunk_total": 1,
  "doc_id": "consumer.go.kr:consumer_counsel_case:53321"
}
```

**ìƒíƒœ**: âœ… ì •ìƒ (0-based)  
**ì•¡ì…˜**: ë³€í™˜ ë¶ˆí•„ìš”

---

### 2. criteria/table2 (í•´ê²°ê¸°ì¤€) âš ï¸

```json
{
  "row_idx": 1,          // âš ï¸ 1-based (1~126)
  "chunk_id": "table2_row_p1_...",
  "text": "..."
}
```

**ë¬¸ì œ**:
- `chunk_index` í•„ë“œ ì—†ìŒ
- `row_idx`ëŠ” 1ë¶€í„° ì‹œì‘ (1-based)
- ì „ì²´ 126ê°œ row: 1, 2, 3, ..., 126

**í•´ê²° ë°©ë²•**:
```python
# ë³€í™˜ ì‹œ 0-basedë¡œ ë³€ê²½
chunk_index = row_idx - 1  # 1 â†’ 0, 2 â†’ 1, 3 â†’ 2, ...
```

---

### 3. dispute_resolution/kca_final âš ï¸

```json
{
  "case_index": 1,       // âš ï¸ ì´ê²ƒì€ ë¬¸ì„œ ë²ˆí˜¸ (case 1, 2, 3...)
  "case_no": "2015ì¼ê°€27",
  "chunk_type": "decision"
}
```

**ë¬¸ì œ**:
- `chunk_index` í•„ë“œ ì—†ìŒ
- `case_index`ëŠ” **ë¬¸ì„œ ë²ˆí˜¸**ì´ì§€ ì²­í¬ ì¸ë±ìŠ¤ê°€ ì•„ë‹˜
- ê°™ì€ case_noì— ì—¬ëŸ¬ ì²­í¬ (decision, parties_claim, judgment)

**í•´ê²° ë°©ë²•**:
```python
# case_noë³„ë¡œ ê·¸ë£¹í™” í›„ ì²­í¬ ì¸ë±ìŠ¤ í• ë‹¹
chunks_by_case = {}
for item in data:
    case_no = item['case_no']
    if case_no not in chunks_by_case:
        chunks_by_case[case_no] = []
    chunks_by_case[case_no].append(item)

# ê° ì¼€ì´ìŠ¤ë³„ë¡œ 0ë¶€í„° ì¸ë±ìŠ¤ ë¶€ì—¬
for case_no, chunks in chunks_by_case.items():
    for idx, chunk in enumerate(chunks):
        chunk['chunk_index'] = idx  # 0, 1, 2, ...
        chunk['chunk_total'] = len(chunks)
```

---

### 4. dispute_resolution/ecmc âš ï¸

```json
{
  "seq": 1,              // âš ï¸ 1-based
  "case_index": 1,       // âš ï¸ ë¬¸ì„œ ë²ˆí˜¸
  "case_no": "CA09-02073",
  "chunk_type": "decision"
}
```

**ë¬¸ì œ**:
- `chunk_index` í•„ë“œ ì—†ìŒ
- `seq`ëŠ” 1ë¶€í„° ì‹œì‘
- `case_index`ëŠ” ë¬¸ì„œ ë²ˆí˜¸

**í•´ê²° ë°©ë²•**:
```python
# case_noë³„ë¡œ ê·¸ë£¹í™” í›„ 0-based ì¸ë±ìŠ¤ í• ë‹¹
# (kca_finalê³¼ ë™ì¼í•œ ë°©ì‹)
```

---

### 5. law (ë²•ë ¹) âš ï¸

```json
{
  "unit_id": "001706|A1",
  "law_id": "001706",
  "law_name": "ë¯¼ë²•"
}
```

**ë¬¸ì œ**:
- `chunk_index` í•„ë“œ ì—†ìŒ
- ì¡°ë¬¸ ë‹¨ìœ„ë¡œ ë‚˜ë‰˜ì–´ ìˆì§€ë§Œ ì¸ë±ìŠ¤ ì—†ìŒ

**í•´ê²° ë°©ë²•**:
```python
# law_idë³„ë¡œ ê·¸ë£¹í™” í›„ 0-based ì¸ë±ìŠ¤ í• ë‹¹
chunks_by_law = {}
for item in data:
    law_id = item['law_id']
    if law_id not in chunks_by_law:
        chunks_by_law[law_id] = []
    chunks_by_law[law_id].append(item)

for law_id, chunks in chunks_by_law.items():
    for idx, chunk in enumerate(chunks):
        chunk['chunk_index'] = idx
        chunk['chunk_total'] = len(chunks)
```

---

## ğŸ”¥ ì„ë² ë”© ì¤‘ ë°œìƒ ê°€ëŠ¥í•œ ì˜¤ë¥˜ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: CHECK ì œì•½ ì¡°ê±´ ìœ„ë°˜

```python
# âŒ ì˜ëª»ëœ ê²½ìš°
INSERT INTO chunks (chunk_id, doc_id, chunk_index, chunk_total, ...)
VALUES ('...', '...', 1, 3, ...)  -- chunk_indexê°€ 1ë¶€í„° ì‹œì‘

# CHECK (chunk_index < chunk_total) ìœ„ë°˜!
# chunk_index=1, chunk_total=3 ì´ë©´ ë§ˆì§€ë§‰ ì²­í¬ëŠ” chunk_index=2ì—¬ì•¼ í•˜ëŠ”ë°
# 1-basedë¡œ í•˜ë©´ chunk_index=3ì´ ë˜ì–´ ì˜¤ë¥˜ ë°œìƒ
```

**ì˜¤ë¥˜ ë©”ì‹œì§€**:
```
psycopg2.errors.CheckViolation: new row for relation "chunks" violates check constraint "chunks_chunk_index_check"
DETAIL: Failing row contains (..., chunk_index=3, chunk_total=3, ...)
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: UNIQUE ì œì•½ ì¡°ê±´ ìœ„ë°˜

```python
# âŒ ì¸ë±ìŠ¤ë¥¼ ì˜ëª» í• ë‹¹í•œ ê²½ìš°
# ê°™ì€ doc_idì— ëŒ€í•´ chunk_indexê°€ ì¤‘ë³µë  ìˆ˜ ìˆìŒ

INSERT INTO chunks (doc_id, chunk_index, ...) VALUES ('doc1', 0, ...)
INSERT INTO chunks (doc_id, chunk_index, ...) VALUES ('doc1', 0, ...)  -- ì¤‘ë³µ!

# UNIQUE(doc_id, chunk_index) ìœ„ë°˜!
```

**ì˜¤ë¥˜ ë©”ì‹œì§€**:
```
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "chunks_doc_id_chunk_index_key"
DETAIL: Key (doc_id, chunk_index)=(doc1, 0) already exists.
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ì„ë² ë”© ë°°ì¹˜ ì¤‘ê°„ ì¤‘ë‹¨

```python
# 10,000ê°œ ì²­í¬ ì¤‘ 5,234ë²ˆì§¸ì—ì„œ ì˜¤ë¥˜ ë°œìƒ
# â†’ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨
# â†’ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘í•´ì•¼ í•¨ (5,233ê°œ ì¬ì„ë² ë”©!)
```

**ì„ë² ë”© ì¬ì‹œì‘ ë¹„ìš©**:
- ì‹œê°„: 5,000ê°œ ì²­í¬ Ã— 0.5ì´ˆ = **~42ë¶„** ë‚­ë¹„
- GPU ë¹„ìš©: RunPod ì‚¬ìš© ì‹œ **$3~5** ë‚­ë¹„
- ì¸ë ¥ ë¹„ìš©: ëª¨ë‹ˆí„°ë§ ë° ì¬ì‹œì‘ ì‹œê°„

---

## âœ… í•´ê²° ë°©ì•ˆ

### 1. ë°ì´í„° ë³€í™˜ ì‹œ í†µì¼ëœ ì¸ë±ì‹± ë¡œì§

```python
class DataTransformer:
    """ëª¨ë“  ë°ì´í„°ë¥¼ 0-based chunk_indexë¡œ í†µì¼"""
    
    def _assign_chunk_indices(self, chunks: List[dict]) -> List[dict]:
        """
        ì²­í¬ ë¦¬ìŠ¤íŠ¸ì— 0-based ì¸ë±ìŠ¤ í• ë‹¹
        
        Args:
            chunks: ê°™ì€ ë¬¸ì„œì˜ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            chunk_index, chunk_totalì´ í• ë‹¹ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        total = len(chunks)
        for idx, chunk in enumerate(chunks):
            chunk['chunk_index'] = idx  # 0, 1, 2, ...
            chunk['chunk_total'] = total
        return chunks
    
    def transform_law_data(self, file_path):
        """ë²•ë ¹ ë°ì´í„° ë³€í™˜ - 0-based ì¸ë±ìŠ¤ í• ë‹¹"""
        chunks_by_law = {}
        
        with open(file_path, 'r') as f:
            for line in f:
                data = json.loads(line)
                law_id = data['law_id']
                
                if law_id not in chunks_by_law:
                    chunks_by_law[law_id] = []
                chunks_by_law[law_id].append(data)
        
        # ê° ë²•ë ¹ë³„ë¡œ 0-based ì¸ë±ìŠ¤ í• ë‹¹
        for law_id, chunks in chunks_by_law.items():
            chunks = self._assign_chunk_indices(chunks)
            self._insert_chunks(f"statute:{law_id}", chunks)
    
    def transform_criteria_table2(self, file_path):
        """ê¸°ì¤€ ë°ì´í„° ë³€í™˜ - row_idxë¥¼ 0-basedë¡œ ë³€í™˜"""
        chunks = []
        
        with open(file_path, 'r') as f:
            for line in f:
                data = json.loads(line)
                chunks.append(data)
        
        # 0-based ì¸ë±ìŠ¤ í• ë‹¹ (row_idxëŠ” ë¬´ì‹œ)
        chunks = self._assign_chunk_indices(chunks)
        self._insert_chunks('criteria:table2', chunks)
    
    def transform_mediation_kca(self, file_path):
        """ë¶„ìŸì¡°ì •ì‚¬ë¡€ ë³€í™˜ - case_noë³„ë¡œ 0-based ì¸ë±ìŠ¤ í• ë‹¹"""
        chunks_by_case = {}
        
        with open(file_path, 'r') as f:
            for line in f:
                data = json.loads(line)
                case_no = data['case_no']
                
                if case_no not in chunks_by_case:
                    chunks_by_case[case_no] = []
                chunks_by_case[case_no].append(data)
        
        # ê° ì¼€ì´ìŠ¤ë³„ë¡œ 0-based ì¸ë±ìŠ¤ í• ë‹¹
        for case_no, chunks in chunks_by_case.items():
            chunks = self._assign_chunk_indices(chunks)
            self._insert_chunks(f"kca:mediation:{case_no}", chunks)
```

### 2. ë³€í™˜ ì „ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

```python
def validate_chunk_indices_before_insert():
    """
    DB ì‚½ì… ì „ chunk_index ê²€ì¦
    - 0ë¶€í„° ì‹œì‘í•˜ëŠ”ì§€
    - ì—°ì†ì ì¸ì§€
    - chunk_totalê³¼ ì¼ì¹˜í•˜ëŠ”ì§€
    """
    for doc_id, chunks in documents.items():
        # ì¸ë±ìŠ¤ ì •ë ¬
        chunks.sort(key=lambda x: x['chunk_index'])
        
        # ê²€ì¦
        expected_indices = list(range(len(chunks)))
        actual_indices = [c['chunk_index'] for c in chunks]
        
        if expected_indices != actual_indices:
            raise ValueError(
                f"Invalid chunk_index for {doc_id}:\n"
                f"  Expected: {expected_indices}\n"
                f"  Actual: {actual_indices}"
            )
        
        # chunk_total ê²€ì¦
        for chunk in chunks:
            if chunk['chunk_total'] != len(chunks):
                raise ValueError(
                    f"Invalid chunk_total for {chunk['chunk_id']}:\n"
                    f"  Expected: {len(chunks)}\n"
                    f"  Actual: {chunk['chunk_total']}"
                )
        
        print(f"âœ… {doc_id}: {len(chunks)} chunks validated")
```

### 3. ì•ˆì „í•œ ë°°ì¹˜ ì‚½ì…

```python
def safe_batch_insert(chunks: List[dict], batch_size: int = 100):
    """
    ì•ˆì „í•œ ë°°ì¹˜ ì‚½ì… - ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¬ì‹œì‘ ì§€ì  ê¸°ë¡
    """
    total = len(chunks)
    
    for i in range(0, total, batch_size):
        batch = chunks[i:i+batch_size]
        
        try:
            # ë°°ì¹˜ ì‚½ì…
            cursor.executemany("""
                INSERT INTO chunks (...)
                VALUES (...)
            """, batch)
            conn.commit()
            
            # ì§„í–‰ ìƒí™© ì €ì¥
            save_progress(i + len(batch))
            
            print(f"âœ… Batch {i//batch_size + 1}/{(total+batch_size-1)//batch_size}: "
                  f"{i + len(batch)}/{total} chunks inserted")
            
        except Exception as e:
            conn.rollback()
            print(f"âŒ Error at batch {i//batch_size + 1} (chunk {i}):")
            print(f"   {e}")
            
            # ë¬¸ì œê°€ ëœ ì²­í¬ ì¶œë ¥
            for idx, chunk in enumerate(batch):
                print(f"   [{idx}] chunk_id={chunk['chunk_id']}, "
                      f"chunk_index={chunk['chunk_index']}, "
                      f"chunk_total={chunk['chunk_total']}")
            
            raise
```

---

## ğŸ“‹ ë³€í™˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë³€í™˜ ì „ í•„ìˆ˜ í™•ì¸ ì‚¬í•­

- [ ] **ëª¨ë“  chunk_indexê°€ 0ë¶€í„° ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸**
- [ ] **ê°™ì€ doc_id ë‚´ì—ì„œ chunk_indexê°€ ì—°ì†ì ì¸ì§€ í™•ì¸**
- [ ] **chunk_index < chunk_total ì¡°ê±´ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸**
- [ ] **UNIQUE(doc_id, chunk_index) ìœ„ë°˜ ì—†ëŠ”ì§€ í™•ì¸**

### íŒŒì¼ë³„ ë³€í™˜ ì „ëµ

#### âœ… compensation_case
- [x] ì´ë¯¸ 0-based
- [ ] ê·¸ëŒ€ë¡œ ì‚¬ìš©
- [ ] ê²€ì¦ë§Œ ìˆ˜í–‰

#### âš ï¸ criteria/table2
- [ ] row_idx ë¬´ì‹œ
- [ ] ìƒˆë¡œìš´ 0-based ì¸ë±ìŠ¤ í• ë‹¹
- [ ] ê²€ì¦ ìˆ˜í–‰

#### âš ï¸ dispute_resolution/kca_final
- [ ] case_noë³„ ê·¸ë£¹í™”
- [ ] ê° ê·¸ë£¹ì— 0-based ì¸ë±ìŠ¤ í• ë‹¹
- [ ] ê²€ì¦ ìˆ˜í–‰

#### âš ï¸ dispute_resolution/ecmc
- [ ] case_noë³„ ê·¸ë£¹í™”
- [ ] ê° ê·¸ë£¹ì— 0-based ì¸ë±ìŠ¤ í• ë‹¹
- [ ] drop=true ì²­í¬ í¬í•¨í•˜ì—¬ ì¸ë±ìŠ¤ í• ë‹¹ (ë‚˜ì¤‘ì— ê²€ìƒ‰ë§Œ ì œì™¸)
- [ ] ê²€ì¦ ìˆ˜í–‰

#### âš ï¸ law
- [ ] law_idë³„ ê·¸ë£¹í™”
- [ ] ê° ë²•ë ¹ì— 0-based ì¸ë±ìŠ¤ í• ë‹¹
- [ ] ê²€ì¦ ìˆ˜í–‰

---

## ğŸ”§ ìˆ˜ì •ëœ ìŠ¤í‚¤ë§ˆ í™•ì¸

í˜„ì¬ ìŠ¤í‚¤ë§ˆ (`schema_v2_final.sql`)ëŠ” ì´ë¯¸ 0-basedë¥¼ ì§€ì›í•©ë‹ˆë‹¤:

```sql
CHECK (chunk_index >= 0)  -- âœ… 0ë¶€í„° ì‹œì‘ í—ˆìš©
CHECK (chunk_total > 0)
CHECK (chunk_index < chunk_total)  -- âœ… 0-based ì „ì œ
```

**ì˜ˆì‹œ**:
- chunk_total = 3ì¸ ë¬¸ì„œ
- ìœ íš¨í•œ chunk_index: 0, 1, 2 âœ…
- ë¬´íš¨í•œ chunk_index: 1, 2, 3 âŒ (3 < 3 ìœ„ë°˜)

---

## ğŸ“Š ì˜ˆìƒ ë³€í™˜ ê²°ê³¼

### ë³€í™˜ ì „ (ì›ë³¸ ë°ì´í„°)

| íŒŒì¼ | ì¸ë±ìŠ¤ í•„ë“œ | ë²”ìœ„ |
|-----|-----------|------|
| compensation_case | chunk_index | 0~ |
| table2 | row_idx | 1~126 |
| kca_final | (ì—†ìŒ) | N/A |
| ecmc | seq | 1~ |
| law | (ì—†ìŒ) | N/A |

### ë³€í™˜ í›„ (DB ì‚½ì…)

| íŒŒì¼ | chunk_index | chunk_total | ê²€ì¦ |
|-----|------------|------------|------|
| compensation_case | 0~ | âœ“ | âœ… |
| table2 | 0~125 | 126 | âœ… |
| kca_final (case 1) | 0~2 | 3 | âœ… |
| ecmc (case 1) | 0~2 | 3 | âœ… |
| law (ë¯¼ë²•) | 0~1751 | 1752 | âœ… |

---

## âš¡ ê¸´ê¸‰ ì•¡ì…˜ ì•„ì´í…œ

### 1. ì¦‰ì‹œ ìˆ˜í–‰ (Priority: HIGH)

```python
# ë°ì´í„° ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ í•¨ìˆ˜ í•„ìˆ˜ í¬í•¨
def _assign_chunk_indices(self, chunks: List[dict]) -> List[dict]:
    """ëª¨ë“  ì²­í¬ì— 0-based ì¸ë±ìŠ¤ í• ë‹¹"""
    total = len(chunks)
    for idx, chunk in enumerate(chunks):
        chunk['chunk_index'] = idx
        chunk['chunk_total'] = total
    return chunks
```

### 2. ë³€í™˜ ì „ í…ŒìŠ¤íŠ¸ (Priority: HIGH)

```bash
# ì‘ì€ ìƒ˜í”Œë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸
cd /home/maroco/ddoksori_demo/backend
conda activate ddoksori

# 1. ìŠ¤í‚¤ë§ˆ ì ìš©
docker exec -it ddoksori_db psql -U postgres -d ddoksori -f /schema/schema_v2_final.sql

# 2. ìƒ˜í”Œ ë°ì´í„° ë³€í™˜ (ê° íŒŒì¼ì—ì„œ 10ê°œì”©ë§Œ)
python scripts/test_transform_sample.py

# 3. chunk_index ê²€ì¦
python scripts/validate_chunk_indices.py

# 4. ë¬¸ì œ ì—†ìœ¼ë©´ ì „ì²´ ë³€í™˜
python scripts/data_transform_pipeline.py
```

### 3. ë³€í™˜ í›„ ê²€ì¦ (Priority: HIGH)

```sql
-- 1. ëª¨ë“  chunk_indexê°€ 0ë¶€í„° ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
SELECT doc_id, MIN(chunk_index) as min_idx
FROM chunks
GROUP BY doc_id
HAVING MIN(chunk_index) != 0;
-- ê²°ê³¼: 0ê°œì—¬ì•¼ í•¨

-- 2. chunk_indexê°€ ì—°ì†ì ì¸ì§€ í™•ì¸
SELECT doc_id, chunk_total, COUNT(*) as actual_count
FROM chunks
GROUP BY doc_id, chunk_total
HAVING COUNT(*) != chunk_total;
-- ê²°ê³¼: 0ê°œì—¬ì•¼ í•¨

-- 3. chunk_index < chunk_total í™•ì¸
SELECT chunk_id, chunk_index, chunk_total
FROM chunks
WHERE chunk_index >= chunk_total;
-- ê²°ê³¼: 0ê°œì—¬ì•¼ í•¨
```

---

## ğŸ“ ê²°ë¡ 

### ğŸ”´ ì‹¬ê°ë„: HIGH

ì›ë³¸ ë°ì´í„°ì˜ ì¸ë±ì‹± ë°©ì‹ì´ ë¶ˆì¼ì¹˜í•˜ì—¬ **ì„ë² ë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥ì„± ë§¤ìš° ë†’ìŒ**.

### âœ… í•´ê²° ë°©ë²•

1. **ë°ì´í„° ë³€í™˜ ì‹œ ëª¨ë“  chunk_indexë¥¼ 0-basedë¡œ í†µì¼**
2. **ì›ë³¸ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ëŠ” ë¬´ì‹œí•˜ê³  ìƒˆë¡œ í• ë‹¹**
3. **ë³€í™˜ ì „í›„ ê²€ì¦ í•„ìˆ˜**

### âš¡ ë‹¤ìŒ ë‹¨ê³„

1. **ë°ì´í„° ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ì— `_assign_chunk_indices()` í•¨ìˆ˜ ì¶”ê°€**
2. **ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸**
3. **ê²€ì¦ í†µê³¼ í›„ ì „ì²´ ë³€í™˜**
4. **ì„ë² ë”© ì‹œì‘**

---

**ì‘ì„±ì**: Manus AI (RAG ì‹œìŠ¤í…œ ì „ë¬¸ê°€)  
**ìµœì¢… ìˆ˜ì •**: 2026-01-06  
**ìŠ¹ì¸ í•„ìš”**: âš ï¸ ë°ì´í„° ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì „ í•„ë…
