# 데이터 변환 및 테스트 가이드

**작성일**: 2026-01-06  
**목적**: 데이터 변환부터 RAG 테스트까지 전체 프로세스 가이드

---

## 📋 전체 프로세스

```
1. 스키마 적용
    ↓
2. 데이터 변환 (JSON 저장)
    ↓
3. 변환 데이터 검증
    ↓
4. DB 삽입 (선택)
    ↓
5. 임베딩 생성
    ↓
6. RAG 테스트
```

---

## 🚀 실행 순서

### Step 1: 환경 준비

```bash
# 1. 프로젝트 디렉토리로 이동
cd /home/maroco/ddoksori_demo

# 2. Conda 환경 활성화
conda activate ddoksori

# 3. 환경 변수 확인
cat backend/.env

# 필수 환경 변수:
# - DB_HOST=localhost
# - DB_PORT=5432
# - DB_NAME=ddoksori
# - DB_USER=postgres
# - DB_PASSWORD=your_password
# - EMBED_API_URL=http://localhost:8001/embed
```

### Step 2: 스키마 적용

```bash
# 1. Docker 컨테이너 시작
docker-compose up -d

# 2. 스키마 파일을 컨테이너에 복사
docker cp backend/database/schema_v2_final.sql ddoksori_db:/tmp/schema_v2_final.sql

# 3. 스키마 적용
docker exec -it ddoksori_db psql -U postgres -d ddoksori -f /tmp/schema_v2_final.sql

# 또는 한 줄로 실행 (cat과 파이프 사용)
cat backend/database/schema_v2_final.sql | docker exec -i ddoksori_db psql -U postgres -d ddoksori

# 4. 적용 확인
docker exec -it ddoksori_db psql -U postgres -d ddoksori -c "\dt"
# 출력: documents, chunks, chunk_relations 테이블 확인

docker exec -it ddoksori_db psql -U postgres -d ddoksori -c "SELECT * FROM v_data_statistics;"
# 출력: 빈 테이블 (정상)
```

### Step 3: 데이터 변환 (JSON 저장)

```bash
# 데이터 변환 실행 (JSON 파일로 저장)
# 💡 어느 디렉토리에서 실행해도 작동합니다!
# 💡 자동으로 청크 최적화 및 메타데이터 보강이 수행됩니다!

# 방법 1: backend 디렉토리에서 (추천)
cd backend
python scripts/data_transform_pipeline.py

# 방법 2: 프로젝트 루트에서
python backend/scripts/data_processing/data_transform_pipeline.py

# 방법 3: scripts 디렉토리에서
cd backend/scripts
python data_transform_pipeline.py

# 예상 출력:
# ✅ 메타데이터 보강 활성화
# ================================================================================
# 데이터 변환 시작
# ================================================================================
# 
# ================================================================================
# 1. 법령 데이터 변환
# ================================================================================
# 📜 법령 데이터 변환: backend/data/law/Civil_Law_chunks.jsonl
#   ✅ 민법: 792개 청크 (최적화 완료)
#   💾 저장: backend/data/transformed/law_civil_law.json
# 
# ...
# 
# ================================================================================
# 변환 완료 통계
# ================================================================================
#   - 총 문서: 11,976개
#   - 총 청크: 14,337개
#   - 스킵: 0개
#   - 메타데이터 보강: 14,027개 청크
#   - 오류: 0개
# 
# ✅ 변환 완료! 결과는 backend/data/transformed/ 에 저장되었습니다.
```

**주요 기능**:
- ✅ **청크 최적화**: 짧은 청크 병합 및 긴 청크 분할 자동 수행
- ✅ **메타데이터 보강**: 키워드, 엔티티, 법률 용어 등 자동 추출
- ✅ **빈 청크 처리**: 빈 청크 자동 `drop=True` 설정

자세한 내용은 [청크 최적화 및 메타데이터 보강](./청크_최적화_및_메타데이터_보강.md) 문서를 참고하세요.

**생성되는 파일**:
- `backend/data/transformed/law_civil_law.json`
- `backend/data/transformed/criteria_table2.json`
- `backend/data/transformed/mediation_kca.json`
- `backend/data/transformed/mediation_ecmc.json`
- `backend/data/transformed/counsel_cs_114.json`
- `backend/data/transformed/transformation_summary.json`

### Step 4: 변환 데이터 검증

```bash
# 검증 실행
python scripts/validate_transformed_data.py

# 예상 출력:
# ================================================================================
# 변환된 데이터 로드
# ================================================================================
# ✅ 로드: law_civil_law.json
# ✅ 로드: criteria_table2.json
# ✅ 로드: mediation_kca.json
# ✅ 로드: mediation_ecmc.json
# ✅ 로드: counsel_cs_114.json
# 
# ✅ 5개 파일 로드 완료
# 
# ================================================================================
# 샘플 데이터 미리보기
# ================================================================================
# ...
# 
# ================================================================================
# 변환 데이터 검증 시작
# ================================================================================
# ...
# 
# ================================================================================
# 검증 결과
# ================================================================================
# 
# 📊 통계:
#   - 총 문서: 16,728개
#   - 총 청크: 22,456개
# 
# 🔍 이슈:
#   - 오류: 0개
#   - 경고: 5개
# 
# ================================================================================
# ✅ 검증 통과! 임베딩 진행 가능합니다.
# ================================================================================
# 
# 💾 검증 결과 저장: backend/data/transformed/validation_result.json
```

**검증 항목**:
- ✅ chunk_index가 0부터 시작
- ✅ chunk_index가 연속적
- ✅ chunk_total이 일치
- ✅ chunk_index < chunk_total
- ✅ 필수 필드 존재
- ✅ content가 비어있지 않음
- ✅ 청크 크기 최적화 (100-2000자 범위)
- ✅ 타입별 최소/최대 길이 준수
- ✅ 메타데이터 품질 확인

### Step 5: 변환 데이터 검토 (선택)

```bash
# JSON 파일 직접 확인
cd backend/data/transformed

# 1. 변환 요약 확인
cat transformation_summary.json | jq '.'

# 2. 검증 결과 확인
cat validation_result.json | jq '.stats'

# 3. 샘플 문서 확인
cat law_civil_law.json | jq '.documents[0]'

# 4. 샘플 청크 확인
cat mediation_kca.json | jq '.documents[0].chunks[0]'
```

### Step 6: DB 삽입 (TODO)

현재 `data_transform_pipeline.py`는 JSON만 생성합니다.
DB 삽입 기능은 추가 구현 필요.

```python
# TODO: data_transform_pipeline.py 수정
# use_db=True로 실행하면 DB에 삽입하도록 구현
```

**임시 방안**: PostgreSQL COPY 명령 사용

```bash
# JSON을 SQL INSERT 문으로 변환 (별도 스크립트 필요)
python scripts/json_to_sql.py

# 또는 Python psycopg2로 직접 삽입
```

### Step 7: 임베딩 생성

```bash
# 1. 임베딩 서버 실행 (별도 터미널)
cd backend
python runpod_embed_server.py

# 출력:
# INFO:     Started server process
# INFO:     Uvicorn running on http://0.0.0.0:8001

# 2. 임베딩 생성 (메인 터미널)
cd backend
python scripts/embed_data.py

# 또는 원격 GPU 사용
python scripts/embed_data_remote.py
```

### Step 8: RAG 테스트

#### 방법 1: 테스트 모드 (미리 정의된 쿼리)

```bash
cd backend
python scripts/test_rag_simple.py --test

# 예상 출력:
# ================================================================================
# 데이터 상태 확인
# ================================================================================
# 
# 📊 문서 통계:
#   - law: 11개
#   - criteria_resolution: 1개
#   - mediation_case: 1,158개
#   - counsel_case: 15,553개
# 
# 📊 청크 통계:
#   [mediation_case]
#     - 총 청크: 3,474개
#     - 임베딩 완료: 3,474개 (100.0%)
#     - 활성 청크: 3,474개
#   [counsel_case]
#     - 총 청크: 15,553개
#     - 임베딩 완료: 15,553개 (100.0%)
#     - 활성 청크: 15,553개
# 
# 🔍 사례 데이터 임베딩 상태:
#   ✅ mediation_case: 사용 가능
#   ✅ counsel_case: 사용 가능
# 
# ✅ RAG 테스트 준비 완료!
# 
# ================================================================================
# RAG 테스트 쿼리 실행
# ================================================================================
# 
# --------------------------------------------------------------------------------
# 🔍 검색 쿼리: 온라인 쇼핑몰에서 구매한 제품이 불량이에요. 환불 받을 수 있나요?
#    top_k: 3, min_similarity: 0.5
#    ✅ 쿼리 임베딩 생성 완료
#    ✅ 3개 결과 발견
# 
# ================================================================================
# 검색 결과
# ================================================================================
# 
# [1] 유사도: 0.8234
#     문서 유형: mediation_case
#     출처: KCA
#     제목: 2015일가27 분쟁조정사례
#     청크 ID: kca:mediation:2015일가27:decision:0000
#     청크 타입: decision
#     길이: 123자
#     내용: 피신청인은 신청인에게 10,000,000원을 지급한다...
#     사건번호: 2015일가27
#     결정일: 2015.05.11
# 
# ...
```

#### 방법 2: 대화형 모드

```bash
cd backend
python scripts/test_rag_simple.py

# 대화형 검색 시작
🔍 검색어: 배송비 과다 청구

# 검색 결과 출력...

🔍 검색어: quit  # 종료
```

---

## 📊 예상 결과

### 변환 데이터 규모

| 데이터 유형 | 문서 수 | 청크 수 | 파일 크기 |
|-----------|--------|--------|---------|
| law | 11 | ~4,000 | ~2MB |
| criteria | 6 | ~900 | ~500KB |
| mediation | ~1,500 | ~3,500 | ~1.5MB |
| counsel | ~15,000 | ~15,000 | ~8MB |
| **합계** | **~16,517** | **~23,400** | **~12MB** |

### 임베딩 소요 시간

| 환경 | 청크 수 | 예상 시간 | 비용 |
|-----|--------|---------|------|
| 로컬 GPU (RTX 3090) | 23,400 | ~20분 | 무료 |
| RunPod (RTX 4090) | 23,400 | ~15분 | $1~2 |
| CPU | 23,400 | ~2시간 | 무료 |

---

## 🔍 검증 체크리스트

### 데이터 변환 후

- [ ] `backend/data/transformed/` 디렉토리에 JSON 파일 생성됨
- [ ] `transformation_summary.json`에 통계 정보 있음
- [ ] 모든 문서에 `doc_id`, `title`, `chunks` 있음
- [ ] 모든 청크에 `chunk_index`, `chunk_total` 있음
- [ ] chunk_index가 0부터 시작
- [ ] chunk_index < chunk_total

### 검증 후

- [ ] `validation_result.json` 생성됨
- [ ] `valid: true` 확인
- [ ] `issues_count: 0` 확인
- [ ] 경고는 있어도 괜찮음 (너무 짧거나 긴 청크 등)

### DB 삽입 후

- [ ] `SELECT COUNT(*) FROM documents;` → 예상 개수
- [ ] `SELECT COUNT(*) FROM chunks;` → 예상 개수
- [ ] `SELECT MIN(chunk_index) FROM chunks;` → 0
- [ ] `SELECT COUNT(*) FROM chunks WHERE chunk_index >= chunk_total;` → 0

### 임베딩 후

- [ ] `SELECT COUNT(*) FROM chunks WHERE embedding IS NOT NULL;` → 전체 청크 수
- [ ] `SELECT array_length(embedding::real[], 1) FROM chunks LIMIT 1;` → 1024

### RAG 테스트 후

- [ ] 검색 결과가 나옴
- [ ] 유사도가 0.0~1.0 범위
- [ ] 관련성 있는 결과 반환

---

## ❌ 문제 해결

### 문제 1: 변환 중 오류

```
❌ ValueError: Invalid chunk_index for doc1
```

**해결**:
1. `data_transform_pipeline.py` 확인
2. `_assign_chunk_indices()` 함수가 제대로 호출되는지 확인
3. 원본 데이터의 인덱스를 무시하고 새로 할당하는지 확인

### 문제 2: 검증 실패

```
❌ 검증 실패! 오류를 수정한 후 다시 시도하세요.
```

**해결**:
1. `validation_result.json` 확인
2. `issues` 배열에서 구체적인 오류 확인
3. 해당 문서의 JSON 파일 직접 확인
4. 변환 로직 수정 후 재실행

### 문제 3: 임베딩 API 연결 실패

```
❌ 임베딩 API 오류: Connection refused
```

**해결**:
1. 임베딩 서버가 실행 중인지 확인
   ```bash
   curl http://localhost:8001/
   ```
2. 포트 번호 확인 (`backend/.env`의 `EMBED_API_URL`)
3. 방화벽 설정 확인

### 문제 4: RAG 테스트 실행 불가

```
❌ RAG 테스트를 실행할 수 없습니다.
```

**해결**:
1. 데이터가 DB에 삽입되었는지 확인
   ```sql
   SELECT COUNT(*) FROM chunks;
   ```
2. 임베딩이 생성되었는지 확인
   ```sql
   SELECT COUNT(*) FROM chunks WHERE embedding IS NOT NULL;
   ```
3. 사례 데이터가 있는지 확인
   ```sql
   SELECT doc_type, COUNT(*) FROM documents GROUP BY doc_type;
   ```

---

## 📝 다음 단계

### 완료됨 ✅
- [x] 스키마 수정 (`schema_v2_final.sql`)
- [x] chunk_index 검토 보고서
- [x] 데이터 변환 스크립트 (JSON 저장)
- [x] 변환 데이터 검증 스크립트
- [x] 간단한 RAG 테스트 스크립트
- [x] 청크 크기 최적화 (병합/분할 로직)
- [x] 메타데이터 보강 기능

### 진행 중 🔄
- [ ] 데이터 변환 실행
- [ ] 변환 결과 검토
- [ ] 스키마 DB 적용

### 대기 중 ⏳
- [ ] DB 삽입 기능 구현
- [ ] 임베딩 생성
- [ ] 전체 RAG 파이프라인 구현
- [ ] 성능 최적화

---

## 📚 관련 문서

- [청크 최적화 및 메타데이터 보강](./청크_최적화_및_메타데이터_보강.md) ⭐ **NEW**
- [데이터 변환 및 스키마 계획서](./데이터_변환_및_스키마_계획.md)
- [chunk_index 검토 보고서](./chunk_index_검토_보고서.md)
- [요구사항 명확화 및 최종 계획](./요구사항_명확화_및_최종_계획.md)
- [임베딩 기준 및 프로세스](./임베딩_기준_및_프로세스.md)

---

**작성자**: Manus AI  
**최종 수정**: 2026-01-06  
**업데이트**: 청크 최적화 및 메타데이터 보강 기능 추가
