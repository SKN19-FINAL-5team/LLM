#     

****: 2026-01-06  
****:          

---

##  

RAG      `validate_transformed_data.py`    .       .

---

##   

###   

- ** 12,150 , 14,898 **
- **92 Critical Issues**:  content  ( mediation_case law )
- **1,797 Warnings**:    
  -   (~10 ): " ", ". " 
  -   (~10,000 ): judgment  

### RAG   

```
  (92) →   →   
  (~1,500) →   →   
  (~300) →   →   
  →   →   
```

---

##   

### 1.     

    /     .

####   (`CHUNK_PROCESSING_RULES`)

```python
CHUNK_PROCESSING_RULES = {
    'decision': {
        'min_length': 50,
        'max_length': 800,
        'drop_if_empty': True
    },
    'reasoning': {
        'min_length': 100,
        'max_length': 1500,
    },
    'judgment': {
        'min_length': 200,
        'max_length': 1500,
    },
    'law': {
        'min_length': 30,
        'max_length': 2000,
        'drop_if_empty': True,
    },
    'law_reference': {
        'min_length': 20,
        'max_length': 2000,
        'drop_if_empty': True
    },
    'resolution_row': {
        'min_length': 50,
        'max_length': 2000,
    },
    'qa_combined': {
        'min_length': 100,
        'max_length': 1500,
    },
    'default': {
        'min_length': 100,
        'max_length': 1500,
        'drop_if_empty': True
    }
}
```

####    

|   |   |   |   |
|----------|----------|----------|----------|
| `decision` | 50 | 800 |   drop |
| `reasoning` | 100 | 1,500 | - |
| `judgment` | 200 | 1,500 | - |
| `law` | 30 | 2,000 |   drop |
| `law_reference` | 20 | 2,000 |   drop |
| `resolution_row` | 50 | 2,000 | - |
| `qa_combined` | 100 | 1,500 | - |
| `default` | 100 | 1,500 |   drop |

### 2.     

      .

```python
def has_meaningful_content(content: str) -> bool:
    """   """
    if not content or not content.strip():
        return False
    
    cleaned = content.strip()
    
    # 1.   
    if len(cleaned) < 5:
        return False
    
    # 2.   
    meaningless_patterns = [
        r'^[-]\.$',      #   +  (: ".", ".")
        r'^[0-9]+\.$',       #  +  (: "1.", "2.")
        r'^[\s\n\r\t]+$',    # 
        r'^[-=_*#]+$',       # 
    ]
    
    for pattern in meaningless_patterns:
        if re.match(pattern, cleaned):
            return False
    
    # 3. /   5   
    text_chars = re.findall(r'[-a-zA-Z]', cleaned)
    if len(text_chars) < 5:
        return False
    
    return True
```

####    

-   + : ".", ".", "."
- : "1.", "2.", "3."
-   
-   
- /  5  

### 3.    

UTF-8       .

```python
def check_encoding_quality(content: str) -> Tuple[bool, str]:
    """     """
    if not content:
        return False, " "
    
    try:
        # UTF-8   
        content.encode('utf-8')
    except UnicodeEncodeError as e:
        return False, f"UTF-8  : {e}"
    
    #     (    )
    total_chars = len(content)
    if total_chars == 0:
        return False, " "
    
    #   (, , , ,  )
    normal_chars = len(re.findall(
        r'[-a-zA-Z0-9\s.,!?;:()\[\]{}"\'-]', 
        content
    ))
    normal_ratio = normal_chars / total_chars
    
    if normal_ratio < 0.8:  #   80%  
        return False, f"    ({normal_ratio:.1%})"
    
    return True, ""
```

####  

1. **UTF-8   **:   
2. **  **:   80%  

### 4.    

      .

```python
def validate_content_quality(self, doc_data: Dict) -> bool:
    """   """
    doc_id = doc_data['doc_id']
    is_valid = True
    
    for chunk in doc_data.get('chunks', []):
        content = chunk.get('content', '')
        content_length = chunk.get('content_length', 0)
        chunk_type = chunk.get('chunk_type', 'default')
        chunk_id = chunk.get('chunk_id', 'unknown')
        should_drop = chunk.get('drop', False)
        
        #    
        rules = CHUNK_PROCESSING_RULES.get(
            chunk_type, 
            CHUNK_PROCESSING_RULES['default']
        )
        min_length = rules['min_length']
        max_length = rules['max_length']
        
        # 1.    (Critical)
        if not content or not content.strip():
            if should_drop:
                self.stats[f'dropped_empty_{chunk_type}'] += 1
            elif rules.get('drop_if_empty', False):
                self.warnings.append(...)  # drop=True 
            else:
                self.issues.append(...)  # Critical 
                is_valid = False
            continue
        
        # 2.    (Critical)
        encoding_ok, encoding_msg = check_encoding_quality(content)
        if not encoding_ok:
            self.issues.append(...)
            is_valid = False
            continue
        
        # 3.    
        if not has_meaningful_content(content):
            if should_drop:
                self.stats[f'dropped_meaningless_{chunk_type}'] += 1
            else:
                self.warnings.append(...)  # drop=True 
        
        # 4.    
        if content_length < min_length and not should_drop:
            self.warnings.append(...)
            self.stats[f'too_short_{chunk_type}'] += 1
        
        # 5.    
        if content_length > max_length:
            self.warnings.append(...)
            self.stats[f'too_long_{chunk_type}'] += 1
        
        # 6. RAG    (100-2000)
        if not should_drop:
            if 100 <= content_length <= 2000:
                self.stats['optimal_chunks'] += 1
            elif content_length < 100:
                self.stats['suboptimal_too_short'] += 1
            else:
                self.stats['suboptimal_too_long'] += 1
    
    return is_valid
```

####  

1. **  **: Critical   drop 
2. **  **: UTF-8    
3. **   **:    
4. ** /  **:   
5. **RAG   **: 100-2000  

### 5.    

    .

```
  :
  -  : 11,976
  -  : 15,238

 RAG   (100-2000 ):
  -  : 13,332 (88.5%)
  -  : 1,408 (9.3%)
  -  : 320 (2.1%)

    :
  -  (decision):
    •  : 57
    •  : 92
  -   (judgment):
    •  : 14
    •  : 311
  ...

 :
  -  Critical : 0
  -   : 2,723

  :
  -    
  -    
```

---

##   

### Before vs After

|  |   |   |  |
|------|---------|---------|--------|
| **Critical Issues** | 92 | **0** | **100%**  |
| ** ** |  | **8 ** |  |
| ** ** |  | **** |  |
| ** ** |  | **** |  |
| **RAG  ** |  | **** |  |
| **  ** | - | **88.5%** |  |

###   

```
  !   .
   (    )

 : 11,976
 : 15,238

 RAG  :
  -   (100-2000): 13,332 (88.5%) 
  -  : 1,408 (9.3%)
  -  : 320 (2.1%)

 :
  -  Critical : 0 ( 92 → 0) 
  -   : 2,723
```

---

##   

###  

```bash
# 1.   
cd /home/maroco/ddoksori_demo

# 2. Conda  
conda activate ddoksori

# 3.   
python backend/scripts/data_processing/validate_transformed_data.py
```

###   

    :

```
backend/data/transformed/validation_result.json
```

####   

```json
{
  "valid": true,
  "issues_count": 0,
  "warnings_count": 2723,
  "issues": [],
  "warnings": [
    "  ...",
    ...
  ],
  "stats": {
    "total_documents": 11976,
    "total_chunks": 15238,
    "optimal_chunks": 13332,
    "suboptimal_too_short": 1408,
    "suboptimal_too_long": 320,
    ...
  }
}
```

---

##    

###  1:  content  

****: ` content `  

****: 
-    
-     

** **:

1. **drop=True ** ()
   ```python
   # data_transform_pipeline.py
   if not content or not content.strip():
       chunk['drop'] = True
   ```

2. **   **
   ```python
   #    
   content = "   : " + ", ".join([
       f"{law.get('law_name', '')} {law.get('article', '')}"
       for law in law_refs
   ])
   ```

###  2:    

****: `    `  

****: 
- " ", ". "   /
-     

** **:

1. **/  ** ()
   ```python
   def merge_short_chunks(chunks, min_length=100):
       merged = []
       buffer = []
       
       for chunk in chunks:
           if len(chunk['content']) < min_length:
               buffer.append(chunk)
           else:
               if buffer:
                   #     
                   merged_content = "\n\n".join(
                       [c['content'] for c in buffer] + [chunk['content']]
                   )
                   chunk['content'] = merged_content
                   buffer = []
               merged.append(chunk)
       
       return merged
   ```

2. **drop=True ** (  )
   ```python
   if not has_meaningful_content(content):
       chunk['drop'] = True
   ```

###  3:    

****: `    `  

****: 
- judgment   3,000 
-    (max 512 tokens)    

** **:

1. **  ** ()
   ```python
   def split_long_chunks(chunk, max_length=1500):
       content = chunk['content']
       
       if len(content) <= max_length:
           return [chunk]
       
       #   
       paragraphs = re.split(r'\n\n+', content)
       
       sub_chunks = []
       current_chunk = []
       current_length = 0
       
       for para in paragraphs:
           if current_length + len(para) > max_length and current_chunk:
               sub_chunks.append({
                   **chunk,
                   'content': "\n\n".join(current_chunk),
                   'chunk_index': len(sub_chunks),
                   'chunk_id': f"{chunk['chunk_id']}_sub{len(sub_chunks)}"
               })
               current_chunk = []
               current_length = 0
           
           current_chunk.append(para)
           current_length += len(para)
       
       #   
       if current_chunk:
           sub_chunks.append({
               **chunk,
               'content': "\n\n".join(current_chunk),
               'chunk_index': len(sub_chunks),
               'chunk_id': f"{chunk['chunk_id']}_sub{len(sub_chunks)}"
           })
       
       return sub_chunks
   ```

###  4:  

****: `  ` 

****: 
- UTF-8   
-   

** **:

1. ** **
   ```python
   #      
   with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
       data = json.load(f)
   ```

2. **  **
   ```python
   #   
   content = content.encode('utf-8', errors='ignore').decode('utf-8')
   ```

###  5:    

****: `   `  

****: 
- ".", "."   
-   

** **:

1. **drop=True ** ()
   ```python
   if not has_meaningful_content(content):
       chunk['drop'] = True
   ```

2. ** ** ( )
   ```python
   #     
   # has_meaningful_content   
   ```

---

##     

### decision ()

- ** **: 50
- ** **: 800
- ** **:   drop
- ****:   ( )

### reasoning ( )

- ** **: 100
- ** **: 1,500
- ****: / 

### judgment ( )

- ** **: 200
- ** **: 1,500
- ****:   ( )

### law ( )

- ** **: 30
- ** **: 2,000
- ** **:   drop,   

### law_reference ( )

- ** **: 20
- ** **: 2,000
- ** **:   drop

### resolution_row (  )

- ** **: 50
- ** **: 2,000
- ****:    

### qa_combined (- )

- ** **: 100
- ** **: 1,500
- ****:  

---

##  RAG  

###   

- ****: 100 ( 30 tokens)
- ****: 300-800 ( 100-250 tokens)
- ****: 2,000 ( 600 tokens)

###  

1. **Critical Issues ** ( )
   -   
   - drop=True    

2. **  ** (9.3%)
   -   
   -  

3. **  ** (2.1%)
   -   
   -   

---

##   

- ** **: `backend/scripts/data_processing/validate_transformed_data.py`
- ** **: `backend/scripts/data_processing/data_transform_pipeline.py`
- ** **: `backend/data/transformed/validation_result.json`
- **  **: `docs/____.md`

---

##   

- **2026-01-06**:       
  -     
  -      
  -     
  -     
  -     

---

##    

###   

1. ** **
   -   (TF-IDF)
   -   (NER)
   -  

2. **Hybrid Search **
   - Vector Search + Metadata Filtering
   -   

3. **  **
   -   
   -  norm   

---

****: AI Assistant  
** **: 2026-01-06
