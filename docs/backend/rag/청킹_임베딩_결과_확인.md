#      

****: 2026-01-05  
****:  (ddoksori_demo)

---

##  

1. [  ](#1---)
2. [Python  ](#2-python--)
3. [  ](#3---)
4. [  ](#4---)
5. [  ](#5---)
6. [](#6-)

---

## 1.   

###  1-1: psql 

```bash
# PostgreSQL 
psql -h localhost -p 5432 -U postgres -d ddoksori

#  Docker  
docker exec -it ddoksori_db psql -U postgres -d ddoksori
```

###   

```sql
-- 1.   
SELECT COUNT(*) as total_documents FROM documents;

-- 2.   
SELECT COUNT(*) as total_chunks FROM chunks;

-- 3.   
SELECT COUNT(*) as embedded_chunks 
FROM chunks 
WHERE embedding IS NOT NULL;

-- 4.   
SELECT 
    doc_type,
    COUNT(*) as document_count
FROM documents
GROUP BY doc_type
ORDER BY doc_type;

-- 5.   
SELECT 
    chunk_type,
    COUNT(*) as chunk_count,
    AVG(content_length) as avg_length
FROM chunks
GROUP BY chunk_type
ORDER BY chunk_count DESC;

-- 6.  
SELECT 
    source_org,
    COUNT(DISTINCT d.doc_id) as document_count,
    COUNT(c.chunk_id) as chunk_count
FROM documents d
LEFT JOIN chunks c ON d.doc_id = c.doc_id
GROUP BY source_org
ORDER BY document_count DESC;
```

###   

```sql
-- 7.   10 
SELECT 
    doc_id,
    doc_type,
    title,
    source_org
FROM documents
LIMIT 10;

-- 8.   10  ( )
SELECT 
    chunk_id,
    doc_id,
    chunk_index,
    chunk_total,
    chunk_type,
    LEFT(content, 100) as content_preview,
    content_length,
    CASE WHEN embedding IS NOT NULL THEN 'YES' ELSE 'NO' END as has_embedding
FROM chunks
LIMIT 10;

-- 9.     
SELECT 
    chunk_id,
    chunk_index,
    chunk_type,
    LEFT(content, 50) as content_preview
FROM chunks
WHERE doc_id = 'consumer.go.kr:consumer_counsel_case:53321'
ORDER BY chunk_index;

-- 10.    Top 10
SELECT 
    chunk_id,
    doc_id,
    content_length,
    LEFT(content, 100) as content_preview
FROM chunks
ORDER BY content_length DESC
LIMIT 10;

-- 11.    Top 10
SELECT 
    chunk_id,
    doc_id,
    content_length,
    content
FROM chunks
ORDER BY content_length ASC
LIMIT 10;
```

###   

```sql
-- 12.    ( +  )
SELECT 
    chunk_id,
    doc_type,
    doc_title,
    chunk_type,
    LEFT(content, 100) as content_preview
FROM v_chunks_with_documents
LIMIT 10;

-- 13.   
SELECT * FROM v_data_statistics;
```

---

## 2. Python  

###  2-1:   

```python
# backend/scripts/check_embedding_status.py
import psycopg2
from dotenv import load_dotenv
import os

load_dotenv()

#  
conn = psycopg2.connect(
    host=os.getenv('DB_HOST', 'localhost'),
    port=os.getenv('DB_PORT', '5432'),
    database=os.getenv('DB_NAME', 'ddoksori'),
    user=os.getenv('DB_USER', 'postgres'),
    password=os.getenv('DB_PASSWORD', 'postgres')
)

cur = conn.cursor()

print("=" * 60)
print("    ")
print("=" * 60)

# 1.  
cur.execute("SELECT COUNT(*) FROM documents")
doc_count = cur.fetchone()[0]
print(f"\n  : {doc_count:,}")

cur.execute("SELECT COUNT(*) FROM chunks")
chunk_count = cur.fetchone()[0]
print(f"  : {chunk_count:,}")

cur.execute("SELECT COUNT(*) FROM chunks WHERE embedding IS NOT NULL")
embedded_count = cur.fetchone()[0]
print(f"  : {embedded_count:,}")
print(f" : {embedded_count/chunk_count*100:.2f}%")

# 2.   
print("\n" + "-" * 60)
print("  ")
print("-" * 60)
cur.execute("""
    SELECT 
        doc_type,
        COUNT(*) as count
    FROM documents
    GROUP BY doc_type
    ORDER BY doc_type
""")
for row in cur.fetchall():
    print(f"  {row[0]:<20} {row[1]:>10,}")

# 3.   
print("\n" + "-" * 60)
print("  ")
print("-" * 60)
cur.execute("""
    SELECT 
        chunk_type,
        COUNT(*) as count,
        AVG(content_length) as avg_length
    FROM chunks
    GROUP BY chunk_type
    ORDER BY count DESC
    LIMIT 10
""")
for row in cur.fetchall():
    print(f"  {row[0]:<20} {row[1]:>10,}  ( {row[2]:.0f})")

# 4.   
print("\n" + "-" * 60)
print("  ")
print("-" * 60)
cur.execute("""
    SELECT 
        MIN(content_length) as min_length,
        AVG(content_length) as avg_length,
        MAX(content_length) as max_length,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY content_length) as median_length
    FROM chunks
""")
row = cur.fetchone()
print(f"   : {row[0]:,}")
print(f"   : {row[1]:.0f}")
print(f"  : {row[2]:.0f}")
print(f"   : {row[3]:,}")

# 5.   
print("\n" + "-" * 60)
print("  (5)")
print("-" * 60)
cur.execute("""
    SELECT 
        chunk_id,
        chunk_type,
        LEFT(content, 100) as content_preview
    FROM chunks
    LIMIT 5
""")
for i, row in enumerate(cur.fetchall(), 1):
    print(f"\n[{i}] {row[0]}")
    print(f"    : {row[1]}")
    print(f"    : {row[2]}...")

print("\n" + "=" * 60)

cur.close()
conn.close()
```

****:
```bash
cd backend
python scripts/check_embedding_status.py
```

---

## 3.   

###  3-1:   

```sql
--   
SELECT 
    doc_type,
    source_org,
    document_count,
    chunk_count,
    avg_chunk_length,
    embedded_chunk_count,
    ROUND(embedded_chunk_count::numeric / chunk_count * 100, 2) as embedding_rate
FROM v_data_statistics
ORDER BY doc_type, source_org;
```

###  3-2:   

```sql
--   
SELECT 
    COUNT(*) as total_chunks,
    COUNT(CASE WHEN embedding IS NOT NULL THEN 1 END) as embedded_chunks,
    ROUND(COUNT(CASE WHEN embedding IS NOT NULL THEN 1 END)::numeric / COUNT(*) * 100, 2) as progress_percent
FROM chunks;

--    
SELECT 
    d.doc_type,
    COUNT(c.chunk_id) as total_chunks,
    COUNT(CASE WHEN c.embedding IS NOT NULL THEN 1 END) as embedded_chunks,
    ROUND(COUNT(CASE WHEN c.embedding IS NOT NULL THEN 1 END)::numeric / COUNT(c.chunk_id) * 100, 2) as progress_percent
FROM documents d
JOIN chunks c ON d.doc_id = c.doc_id
GROUP BY d.doc_type
ORDER BY d.doc_type;
```

---

## 4.   

###  4-1:     

```sql
--     
SELECT 
    chunk_index,
    chunk_type,
    content_length,
    LEFT(content, 200) as content_preview,
    CASE WHEN embedding IS NOT NULL THEN 'YES' ELSE 'NO' END as has_embedding
FROM chunks
WHERE doc_id = 'YOUR_DOC_ID'
ORDER BY chunk_index;
```

###  4-2:   

```sql
--   10 
SELECT 
    c.chunk_id,
    d.doc_type,
    d.title,
    c.chunk_type,
    c.content_length,
    LEFT(c.content, 150) as content_preview
FROM chunks c
JOIN documents d ON c.doc_id = d.doc_id
ORDER BY RANDOM()
LIMIT 10;
```

---

## 5.   

###  5-1:   

```sql
--    
SELECT 
    chunk_id,
    array_length(embedding::real[], 1) as embedding_dimension
FROM chunks
WHERE embedding IS NOT NULL
LIMIT 5;

--     ( 5 )
SELECT 
    chunk_id,
    (embedding::real[])[1:5] as first_5_dimensions
FROM chunks
WHERE embedding IS NOT NULL
LIMIT 5;
```

###  5-2:   

```python
# backend/scripts/test_similarity_search.py
import psycopg2
import requests
import json
from dotenv import load_dotenv
import os

load_dotenv()

#  
conn = psycopg2.connect(
    host=os.getenv('DB_HOST', 'localhost'),
    port=os.getenv('DB_PORT', '5432'),
    database=os.getenv('DB_NAME', 'ddoksori'),
    user=os.getenv('DB_USER', 'postgres'),
    password=os.getenv('DB_PASSWORD', 'postgres')
)

#  
test_query = "    .    ?"

print(f" : {test_query}")
print("=" * 60)

# 1.   
embed_api_url = os.getenv('EMBED_API_URL', 'http://localhost:8001/embed')
response = requests.post(embed_api_url, json={"text": test_query})
query_embedding = response.json()['embedding']

print(f"    (: {len(query_embedding)})")

# 2.  
cur = conn.cursor()
cur.execute("""
    SELECT 
        chunk_id,
        doc_id,
        chunk_type,
        LEFT(content, 200) as content_preview,
        1 - (embedding <=> %s::vector) as similarity
    FROM chunks
    WHERE embedding IS NOT NULL
    ORDER BY embedding <=> %s::vector
    LIMIT 5
""", (query_embedding, query_embedding))

print("\n 5  :")
print("-" * 60)
for i, row in enumerate(cur.fetchall(), 1):
    print(f"\n[{i}] : {row[4]:.4f}")
    print(f"     ID: {row[0]}")
    print(f"     ID: {row[1]}")
    print(f"     : {row[2]}")
    print(f"    : {row[3]}...")

cur.close()
conn.close()
```

****:
```bash
cd backend
python scripts/test_similarity_search.py
```

---

## 6. 

###  6-1:    

```python
# backend/scripts/visualize_chunks.py
import psycopg2
import matplotlib.pyplot as plt
import numpy as np
from dotenv import load_dotenv
import os

load_dotenv()

conn = psycopg2.connect(
    host=os.getenv('DB_HOST', 'localhost'),
    port=os.getenv('DB_PORT', '5432'),
    database=os.getenv('DB_NAME', 'ddoksori'),
    user=os.getenv('DB_USER', 'postgres'),
    password=os.getenv('DB_PASSWORD', 'postgres')
)

cur = conn.cursor()

#    
cur.execute("SELECT content_length FROM chunks")
lengths = [row[0] for row in cur.fetchall()]

#  
plt.figure(figsize=(12, 6))
plt.hist(lengths, bins=50, edgecolor='black', alpha=0.7)
plt.xlabel('  ( )')
plt.ylabel('')
plt.title('  ')
plt.axvline(np.mean(lengths), color='r', linestyle='--', label=f': {np.mean(lengths):.0f}')
plt.axvline(np.median(lengths), color='g', linestyle='--', label=f': {np.median(lengths):.0f}')
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig('chunk_length_distribution.png', dpi=300, bbox_inches='tight')
print("    : chunk_length_distribution.png")

#    
cur.execute("""
    SELECT d.doc_type, COUNT(c.chunk_id)
    FROM documents d
    LEFT JOIN chunks c ON d.doc_id = c.doc_id
    GROUP BY d.doc_type
    ORDER BY d.doc_type
""")
doc_types = []
chunk_counts = []
for row in cur.fetchall():
    doc_types.append(row[0])
    chunk_counts.append(row[1])

plt.figure(figsize=(10, 6))
plt.bar(doc_types, chunk_counts, edgecolor='black', alpha=0.7)
plt.xlabel(' ')
plt.ylabel(' ')
plt.title('   ')
plt.xticks(rotation=45, ha='right')
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig('chunks_by_doc_type.png', dpi=300, bbox_inches='tight')
print("     : chunks_by_doc_type.png")

cur.close()
conn.close()
```

****:
```bash
cd backend
python scripts/visualize_chunks.py
```

---

##   

     :

###   

```sql
-- 1.    
SELECT COUNT(*) FROM chunks;
-- : 30,754

-- 2.   
SELECT 
    COUNT(*) as total,
    COUNT(CASE WHEN embedding IS NOT NULL THEN 1 END) as embedded,
    ROUND(COUNT(CASE WHEN embedding IS NOT NULL THEN 1 END)::numeric / COUNT(*) * 100, 2) as rate
FROM chunks;
-- : 100%

-- 3.   
SELECT doc_type, COUNT(*) FROM documents GROUP BY doc_type;
-- : law(11), counsel_case(13,544), mediation_case(3,173)
```

###   

```sql
-- 4.    
SELECT chunk_id, content_length, content
FROM chunks
WHERE content_length < 10
LIMIT 10;

-- 5.    
SELECT chunk_id, content_length, LEFT(content, 100)
FROM chunks
WHERE content_length > 5000
LIMIT 10;

-- 6.   
SELECT DISTINCT array_length(embedding::real[], 1) as dimension
FROM chunks
WHERE embedding IS NOT NULL;
-- : 1024 (KURE-v1  )
```

###   

```sql
-- 7.    
-- (     )

-- 8.    
SELECT * FROM get_chunk_with_context('consumer.go.kr:consumer_counsel_case:53321::chunk0', 1);
```

---

##   

- [PostgreSQL  ](https://www.postgresql.org/docs/)
- [pgvector ](https://github.com/pgvector/pgvector)
- [RAG  ](backend/RAG_SETUP_GUIDE.md)

---

****: Manus AI  
** **: 2026-01-05
