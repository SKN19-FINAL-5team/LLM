# ë˜‘ì†Œë¦¬ RAG ì‹œìŠ¤í…œ ì²­í‚¹-ì„ë² ë”© ì „ëµ ìƒì„¸ ë¶„ì„

**ì‘ì„±ì¼**: 2026-01-06  
**ëª©ì **: í˜„ì¬ ì²­í‚¹-ì„ë² ë”© ì „ëµ ë° RAG ì•„í‚¤í…ì²˜ ë¶„ì„, ê°œì„ ì  ë„ì¶œ

---

## ğŸ“Š 1. ì²­í‚¹ ì „ëµ ë¶„ì„

### 1.1 ì²­í¬ ì²˜ë¦¬ ê·œì¹™ (CHUNK_PROCESSING_RULES)

í˜„ì¬ ì‹œìŠ¤í…œì€ **íƒ€ì…ë³„ ì°¨ë³„í™”ëœ ì²­í¬ ì²˜ë¦¬ ê·œì¹™**ì„ ì ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.

#### ì²­í¬ íƒ€ì…ë³„ ê·œì¹™

| ì²­í¬ íƒ€ì… | ìµœì†Œ ê¸¸ì´ | ìµœëŒ€ ê¸¸ì´ | ëª©í‘œ ê¸¸ì´ | ë³‘í•© í—ˆìš© | ë¶„í•  í—ˆìš© | Overlap í¬ê¸° |
|-----------|----------|----------|-----------|-----------|-----------|------------|
| `decision` | 100ì | 700ì | 600ì | âŒ | âœ… | 100ì |
| `reasoning` | 150ì | 700ì | 600ì | âœ… | âœ… | 150ì |
| `judgment` | 200ì | 700ì | 600ì | âœ… | âœ… | 150ì |
| `parties_claim` | 150ì | 700ì | 600ì | âœ… | âœ… | 150ì |
| `law` | 50ì | 700ì | 600ì | âŒ | âœ… | 100ì |
| `law_reference` | 50ì | 700ì | 600ì | âŒ | âœ… | 100ì |
| `resolution_row` | 100ì | 700ì | 600ì | âŒ | âœ… | 100ì |
| `qa_combined` | 150ì | 700ì | 600ì | âŒ | âœ… | 100ì |
| `article` | 100ì | 700ì | 600ì | âŒ | âœ… | 100ì |
| `paragraph` | 100ì | 700ì | 600ì | âœ… | âœ… | 100ì |

**í† í° ì œí•œ ê·¼ê±°**:
- KURE-v1 ëª¨ë¸ ìµœëŒ€ í† í°: **512 í† í°**
- í•œêµ­ì–´ ë³€í™˜ìœ¨: **1.5ì â‰ˆ 1í† í°**
- ì•ˆì „ ë²”ìœ„: **500-700ì (ì•½ 250-350 í† í°)**

#### âœ… ê¸ì •ì  ìš”ì†Œ

1. **íƒ€ì…ë³„ ì°¨ë³„í™”**
   - ê° ì²­í¬ íƒ€ì…ì˜ íŠ¹ì„±ì— ë§ëŠ” ì²˜ë¦¬ ê·œì¹™ ì ìš©
   - `decision`ì€ ë…ë¦½ì„± ìœ ì§€ (ë³‘í•© ë¶ˆê°€)
   - `reasoning`, `judgment`ëŠ” ìœ ì—°í•œ ë³‘í•©/ë¶„í•  í—ˆìš©

2. **Overlapping ì ìš©**
   ```python
   # ì²­í¬ ì¬ì¡°í•© ì‹œ ì´ì „ ì²­í¬ì˜ ë ë¶€ë¶„ í¬í•¨
   if previous_tail and sub_chunks:
       chunk_content = previous_tail + '\n\n' + chunk_content
   ```
   - ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ì„ ìœ„í•œ ì¤‘ì²© êµ¬ê°„ (100-150ì)
   - ì˜ë¯¸ ì—°ê²°ì„± ìœ ì§€

3. **ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• **
   ```python
   # 1ìˆœìœ„: ë¬¸ë‹¨ ë‹¨ìœ„ ë¶„í• 
   sections = re.split(r'\n\n+', content)
   
   # 2ìˆœìœ„: ë¬¸ì¥ ë‹¨ìœ„ ë¶„í• 
   sentences = re.split(r'([.!?]\s+)', section)
   ```
   - ê³„ì¸µì  ë¶„í• : ë¬¸ë‹¨ â†’ ë¬¸ì¥
   - ì˜ë¯¸ ê²½ê³„ ì¡´ì¤‘

4. **í† í° ì œí•œ ê²€ì¦**
   ```python
   def _estimate_token_count(self, text: str) -> int:
       char_count = len(text)
       return int(char_count / 1.5)  # ë³´ìˆ˜ì  ì¶”ì •
   ```
   - ì„ë² ë”© ëª¨ë¸ ì œì•½ ì¤€ìˆ˜
   - ìœ„ë°˜ ì²­í¬ ìë™ ì¬ë¶„í• 

5. **ìµœì í™” íŒŒì´í”„ë¼ì¸**
   ```python
   # 1. ì§§ì€ ì²­í¬ ë³‘í•©
   chunks = self._merge_short_chunks(chunks)
   
   # 2. ê¸´ ì²­í¬ ë¶„í• 
   chunks = self._split_long_chunks(chunks)
   
   # 3. ë¹ˆ ì²­í¬ ì²˜ë¦¬
   # ...
   
   # 4. í† í° ì œí•œ ê²€ì¦
   validation_result = self._validate_token_limit(chunks)
   ```
   - ì²´ê³„ì ì¸ 4ë‹¨ê³„ ìµœì í™”

#### âš ï¸ ê°œì„  í•„ìš” ì˜ì—­

1. **ê³ ì • ê¸¸ì´ ì œì•½ì˜ í•œê³„**
   
   **ë¬¸ì œì **: ëª¨ë“  íƒ€ì…ì— 700ì ìµœëŒ€ ê¸¸ì´ ë™ì¼ ì ìš©
   
   ```python
   # í˜„ì¬: ëª¨ë“  íƒ€ì…ì´ 700ì
   'max_length': 700,
   'target_length': 600,
   ```
   
   **íƒ€ì…ë³„ ìµœì  ê¸¸ì´ ì°¨ì´**:
   - `decision`: ê°„ê²°í•œ ê²°ì •ë¬¸ â†’ **500-600ì**ê°€ ì ì ˆ
   - `reasoning`/`judgment`: ìƒì„¸í•œ ë…¼ë¦¬ â†’ **700-800ì** í•„ìš”
   - `law`: ì¡°ë¬¸ ë‹¨ìœ„ â†’ **400-500ì**ë¡œ ì¶©ë¶„
   
   **ê°œì„  ë°©í–¥**: íƒ€ì…ë³„ ìµœì  ê¸¸ì´ ì°¨ë³„í™”

2. **ë©”íƒ€ë°ì´í„° í™œìš© ë¶€ì¡±**
   
   **í˜„ì¬ ìƒíƒœ**:
   ```python
   # ë²•ë ¹ ì²­í¬ ìƒì„±
   chunk = {
       'content': f"[ë²•ë ¹] {data['law_name']}\n[ì¡°ë¬¸] {data['path']}\n\n{data['index_text']}"
   }
   ```
   
   **ë¬¸ì œì **:
   - ë©”íƒ€ë°ì´í„°(ë²•ë ¹ëª…, ì¡°ë¬¸ë²ˆí˜¸)ë¥¼ contentì—ë§Œ í¬í•¨
   - êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì„ë² ë”©ì— ì¶©ë¶„íˆ í™œìš©í•˜ì§€ ëª»í•¨
   - ê²€ìƒ‰ ì‹œ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì œí•œì 
   
   **ê°œì„  ë°©í–¥**:
   - ë©”íƒ€ë°ì´í„°ë¥¼ ë³„ë„ í•„ë“œë¡œ ì €ì¥
   - ê²€ìƒ‰ ì‹œ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§ ê°•í™”
   - ì„ë² ë”© ìƒì„± ì‹œ ë©”íƒ€ë°ì´í„° ê°€ì¤‘ì¹˜ ì ìš©

3. **ì²­í¬ í’ˆì§ˆ ê²€ì¦ ë¶€ì¬**
   
   **í˜„ì¬ ìƒíƒœ**:
   - ê¸¸ì´ì™€ í† í° ìˆ˜ë§Œ ê²€ì¦
   - ì˜ë¯¸ì  ì™„ê²°ì„± ê²€ì¦ ì—†ìŒ
   
   **ë¬¸ì œì **:
   - ë¬¸ì¥ì´ ì¤‘ê°„ì— ëŠê¸´ ì²­í¬ ê°€ëŠ¥
   - ì°¸ì¡° ê´€ê³„ê°€ ëŠì–´ì§„ ì²­í¬ ë°œìƒ
   
   **ê°œì„  ë°©í–¥**:
   - ë¬¸ì¥ ì™„ê²°ì„± ê²€ì¦
   - ì°¸ì¡° ë¬´ê²°ì„± ê²€ì‚¬
   - ì²­í¬ í’ˆì§ˆ ì ìˆ˜ ì‚°ì •

4. **Overlapping ì „ëµì˜ í•œê³„**
   
   **í˜„ì¬ ë°©ì‹**:
   ```python
   # ì´ì „ ì²­í¬ì˜ ë ë¶€ë¶„ì„ ë‹¤ìŒ ì²­í¬ ì•ì— ì¶”ê°€
   previous_tail = chunk_content[-overlap_size:]
   ```
   
   **ë¬¸ì œì **:
   - ë‹¨ìˆœ ë¬¸ì ê¸¸ì´ ê¸°ë°˜ ì¤‘ì²©
   - ì˜ë¯¸ ë‹¨ìœ„ ê³ ë ¤ ì—†ìŒ
   - ì¤‘ë³µ ì •ë³´ë¡œ ì¸í•œ ê²€ìƒ‰ ë…¸ì´ì¦ˆ ê°€ëŠ¥
   
   **ê°œì„  ë°©í–¥**:
   - ë¬¸ì¥ ë‹¨ìœ„ ì¤‘ì²©
   - ì¤‘ìš”ë„ ê¸°ë°˜ overlap ì¡°ì •
   - ì¤‘ë³µ ê°ì§€ ë° ì œê±°

---

## ğŸ”® 2. ì„ë² ë”© ì „ëµ ë¶„ì„

### 2.1 ì„ë² ë”© ëª¨ë¸

**ì‚¬ìš© ëª¨ë¸**: `nlpai-lab/KURE-v1`

**ëª¨ë¸ íŠ¹ì„±**:
- **ì°¨ì›**: 1024ì°¨ì›
- **íŠ¹í™”**: í•œêµ­ì–´ ë²•ë¥ /í–‰ì • ë¬¸ì„œ
- **ìµœëŒ€ í† í°**: 512 í† í°
- **ì„ë² ë”© ë°©ì‹**: Sentence Transformers í”„ë ˆì„ì›Œí¬

**ì¥ì **:
- âœ… í•œêµ­ì–´ ë²•ë¥  ìš©ì–´ ì´í•´ë„ ë†’ìŒ
- âœ… ë¬¸ë§¥ ì˜ì¡´ì  ì„ë² ë”© ìƒì„±
- âœ… íš¨ìœ¨ì ì¸ ì¸ë±ì‹± (1024ì°¨ì›)

### 2.2 ì„ë² ë”© ìƒì„± í”„ë¡œì„¸ìŠ¤

```python
# embed_data_remote.py
class EmbeddingPipeline:
    def __init__(self, db_config, embed_api_url):
        self.embed_api_url = embed_api_url
        self.batch_size = 32  # ë°°ì¹˜ í¬ê¸°
```

**ì²˜ë¦¬ í”Œë¡œìš°**:

1. **ë°°ì¹˜ ì²˜ë¦¬** (32ê°œ ì²­í¬ ë‹¨ìœ„)
   ```python
   for i in range(0, len(chunks_to_embed), self.batch_size):
       batch = chunks_to_embed[i:i + self.batch_size]
       embeddings = self.generate_embeddings(texts)
   ```

2. **ì›ê²© API í˜¸ì¶œ** (RunPod GPU)
   ```python
   response = requests.post(
       self.embed_api_url,
       json={"texts": texts},
       timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
   )
   ```

3. **í’ˆì§ˆ ê²€ì¦** (ìë™)
   ```python
   is_low_quality, reason = self.is_low_quality_embedding(embedding)
   ```

4. **PostgreSQL ì €ì¥** (pgvector)
   ```python
   UPDATE chunks
   SET embedding = %s::vector
   WHERE chunk_id = %s
   ```

#### âœ… ê¸ì •ì  ìš”ì†Œ

1. **í’ˆì§ˆ ê²€ì¦ ë©”ì»¤ë‹ˆì¦˜**
   
   ```python
   def is_low_quality_embedding(self, embedding) -> Tuple[bool, str]:
       vec = np.array(embedding)
       
       # ì²´í¬ 1: Normì´ ë„ˆë¬´ ì‘ìŒ
       if np.linalg.norm(vec) < 0.1:
           return True, "normì´ ë„ˆë¬´ ì‘ìŒ"
       
       # ì²´í¬ 2: ë¶„ì‚°ì´ ë„ˆë¬´ ì‘ìŒ
       if np.var(vec) < 0.001:
           return True, "ë¶„ì‚°ì´ ë„ˆë¬´ ì‘ìŒ"
       
       # ì²´í¬ 3: NaN/Inf ê°’ ì¡´ì¬
       if np.isnan(vec).any() or np.isinf(vec).any():
           return True, "NaN ë˜ëŠ” Inf ê°’ í¬í•¨"
       
       # ì²´í¬ 4: í¬ì†Œ ë²¡í„° (ëŒ€ë¶€ë¶„ 0)
       near_zero = np.abs(vec) < 0.001
       if near_zero.sum() / len(vec) > 0.9:
           return True, "í¬ì†Œ ë²¡í„°"
       
       return False, ""
   ```
   
   **ê²€ì¦ í•­ëª©**:
   - Norm ê²€ì‚¬ (ì˜ë¯¸ ìˆëŠ” ë²¡í„°ì¸ì§€)
   - ë¶„ì‚° ê²€ì‚¬ (ëª¨ë“  ê°’ì´ ìœ ì‚¬í•œì§€)
   - ì´ìƒê°’ ê²€ì‚¬ (NaN, Inf)
   - í¬ì†Œì„± ê²€ì‚¬ (ëŒ€ë¶€ë¶„ 0ì¸ì§€)

2. **íš¨ìœ¨ì  ë°°ì¹˜ ì²˜ë¦¬**
   - GPU í™œìš© ìµœì í™”
   - ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”
   - íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì•ˆì •ì„±)

3. **ë¹ˆ ì½˜í…ì¸  í•„í„°ë§**
   ```python
   chunks_to_embed = [
       (chunk['chunk_id'], chunk['content'])
       for chunk in valid_chunks
       if chunk['content'] and len(chunk['content'].strip()) > 0
   ]
   ```

#### âš ï¸ ê°œì„  í•„ìš” ì˜ì—­

1. **ë‹¨ì¼ ëª¨ë¸ ì˜ì¡´ì„±**
   
   **í˜„ì¬ ìƒíƒœ**: KURE-v1ë§Œ ì‚¬ìš©
   
   **ë¬¸ì œì **:
   - ëª¨ë¸ ì¥ì•  ì‹œ ëŒ€ì•ˆ ì—†ìŒ
   - ë„ë©”ì¸ë³„ ìµœì í™” ë¶ˆê°€
   - ë‹¤êµ­ì–´ ì§€ì› ì œí•œì 
   
   **ê°œì„  ë°©í–¥**:
   - ë©€í‹° ëª¨ë¸ ì§€ì› (í•˜ì´ë¸Œë¦¬ë“œ ì„ë² ë”©)
   - Fallback ëª¨ë¸ ì„¤ì •
   - ë„ë©”ì¸ë³„ ëª¨ë¸ ì„ íƒ ë¡œì§

2. **ì„ë² ë”© í›„ í’ˆì§ˆ ê²€ì¦ë§Œ ì¡´ì¬**
   
   **í˜„ì¬ ìƒíƒœ**:
   - ì„ë² ë”© ìƒì„± í›„ í’ˆì§ˆ ê²€ì‚¬
   - ì‚¬ì „ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì œí•œì 
   
   **ë¬¸ì œì **:
   - ì €í’ˆì§ˆ í…ìŠ¤íŠ¸ê°€ ì„ë² ë”© ìƒì„±ê¹Œì§€ ì§„í–‰
   - ë¹„ìš© ë‚­ë¹„ (GPU ì—°ì‚°)
   
   **ê°œì„  ë°©í–¥**:
   - í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ê°•í™”
   - ì‚¬ì „ í’ˆì§ˆ í•„í„°ë§
   - ì •ê·œí™” ë° ì •ì œ

3. **ì„ë² ë”© ë²„ì „ ê´€ë¦¬ ë¶€ì¬**
   
   **í˜„ì¬ ìƒíƒœ**:
   ```python
   embedding_model VARCHAR(50) DEFAULT 'KURE-v1'
   ```
   
   **ë¬¸ì œì **:
   - ëª¨ë¸ ë³€ê²½ ì‹œ ê¸°ì¡´ ì„ë² ë”© ì¬ìƒì„± í•„ìš”
   - ë²„ì „ ì¶”ì  ì–´ë ¤ì›€
   
   **ê°œì„  ë°©í–¥**:
   - ëª¨ë¸ ë²„ì „ ì •ë³´ ì €ì¥
   - ì¬ì„ë² ë”© íŠ¸ë¦¬ê±° ì„¤ê³„
   - A/B í…ŒìŠ¤íŠ¸ ì§€ì›

---

## ğŸ—ï¸ 3. RAG ì•„í‚¤í…ì²˜ ë¶„ì„

### 3.1 í˜„ì¬ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    User[ì‚¬ìš©ì ì¿¼ë¦¬] --> Embed[ì„ë² ë”© ìƒì„±]
    Embed --> Search[Vector ê²€ìƒ‰]
    Search --> Filter[í•„í„°ë§]
    Filter --> Format[ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…]
    Format --> LLM[LLM ë‹µë³€ ìƒì„±]
    LLM --> Response[ì‘ë‹µ]
```

### 3.2 ê²€ìƒ‰ ë¡œì§ (retriever.py)

```python
def search(
    self, 
    query: str, 
    top_k: int = 5,
    chunk_types: Optional[List[str]] = None,
    agencies: Optional[List[str]] = None
) -> List[Dict]:
    """ë‹¨ì¼ ìŠ¤í…Œì´ì§€ ê²€ìƒ‰"""
    
    # 1. ì¿¼ë¦¬ ì„ë² ë”©
    query_embedding = self.embed_query(query)
    
    # 2. SQL ì¿¼ë¦¬ êµ¬ì„±
    sql = """
        SELECT 
            c.chunk_uid,
            c.case_uid,
            c.chunk_type,
            c.text,
            cs.case_no,
            cs.decision_date,
            cs.agency,
            1 - (c.embedding <=> %s::vector) AS similarity
        FROM chunks c
        JOIN cases cs ON c.case_uid = cs.case_uid
        WHERE c.drop = FALSE
    """
    
    # 3. í•„í„°ë§ (chunk_type, agency)
    if chunk_types:
        sql += f" AND c.chunk_type IN ({placeholders})"
    if agencies:
        sql += f" AND cs.agency IN ({placeholders})"
    
    # 4. ìœ ì‚¬ë„ ì •ë ¬ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
    sql += """
        ORDER BY c.embedding <=> %s::vector
        LIMIT %s
    """
    
    return results
```

**ê²€ìƒ‰ ë°©ì‹**:
- **ì•Œê³ ë¦¬ì¦˜**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (HNSW ì¸ë±ìŠ¤)
- **í•„í„°ë§**: chunk_type, agencyë§Œ ì§€ì›
- **ì •ë ¬**: ìœ ì‚¬ë„ ê¸°ë°˜ ë‹¨ìˆœ ì •ë ¬
- **ìŠ¤í…Œì´ì§€**: ë‹¨ì¼ ìŠ¤í…Œì´ì§€ ê²€ìƒ‰

### 3.3 ë‹µë³€ ìƒì„± ë¡œì§ (generator.py)

```python
def generate_answer(self, query: str, chunks: List[Dict]) -> Dict:
    """LLM ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
    
    # 1. ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
    context = self.format_context(chunks)
    
    # 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompt = """ë‹¹ì‹ ì€ í•œêµ­ì˜ ì†Œë¹„ì ë¶„ìŸ ì¡°ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì•„ë˜ "ì°¸ê³  ìë£Œ"ì— ì œê³µëœ ì‹¤ì œ ë¶„ìŸì¡°ì • ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
    
    **ë‹µë³€ ì‘ì„± ì›ì¹™:**
    1. ë°˜ë“œì‹œ ì œê³µëœ ì°¸ê³  ìë£Œì˜ ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    2. ì°¸ê³  ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
    3. ê´€ë ¨ ì‚¬ë¡€ì˜ ì‚¬ê±´ë²ˆí˜¸, ê²°ì • ë‚´ìš©, ë²•ì  ê·¼ê±°ë¥¼ ëª…í™•íˆ ì¸ìš©í•˜ì„¸ìš”.
    4. ë‹µë³€ì€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•˜ì„¸ìš”.
    5. ì°¸ê³  ìë£Œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ë‹¤ë©´, ì†”ì§í•˜ê²Œ "ì œê³µëœ ìë£Œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”."""
    
    # 3. LLM í˜¸ì¶œ (GPT-4o-mini)
    response = self.client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.3,
        max_tokens=1000
    )
    
    return response
```

**ìƒì„± íŠ¹ì„±**:
- **ëª¨ë¸**: GPT-4o-mini
- **Temperature**: 0.3 (ì¼ê´€ì  ë‹µë³€)
- **ìµœëŒ€ í† í°**: 1000 í† í°
- **í”„ë¡¬í”„íŠ¸**: ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ ê°•ì œ

### 3.4 API ì—”ë“œí¬ì¸íŠ¸ (main.py)

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ê¸°ëŠ¥ |
|-----------|--------|------|
| `/search` | POST | Vector ê²€ìƒ‰ë§Œ (LLM ì—†ìŒ) |
| `/chat` | POST | RAG ê¸°ë°˜ ë‹µë³€ ìƒì„± |
| `/chat/stream` | POST | ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± |
| `/case/{case_uid}` | GET | íŠ¹ì • ì‚¬ë¡€ ì „ì²´ ì¡°íšŒ |

#### âœ… ê¸ì •ì  ìš”ì†Œ

1. **íš¨ìœ¨ì  ë²¡í„° ê²€ìƒ‰**
   ```sql
   -- HNSW ì¸ë±ìŠ¤ ì‚¬ìš©
   CREATE INDEX idx_chunks_embedding 
   ON chunks USING ivfflat(embedding vector_cosine_ops) 
   WITH (lists = 100);
   ```
   - ë¹ ë¥¸ ê·¼ì‚¬ ê²€ìƒ‰
   - ëŒ€ìš©ëŸ‰ ë°ì´í„° ëŒ€ì‘

2. **ìŠ¤íŠ¸ë¦¬ë° ì§€ì›**
   ```python
   def generate_answer_stream(self, query, chunks):
       """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€"""
       stream = self.client.chat.completions.create(
           model=self.model,
           messages=[...],
           stream=True
       )
       
       for chunk in stream:
           if chunk.choices[0].delta.content:
               yield chunk.choices[0].delta.content
   ```
   - ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ
   - ì‹¤ì‹œê°„ ì‘ë‹µ ì œê³µ

3. **ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…**
   ```python
   def format_context(self, chunks: List[Dict]) -> str:
       """ê²€ìƒ‰ëœ ì²­í¬ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
       for idx, chunk in enumerate(chunks, 1):
           case_info = f"[ì‚¬ë¡€ {idx}]"
           case_info += f" ì‚¬ê±´ë²ˆí˜¸: {chunk['case_no']}"
           case_info += f", ê²°ì •ì¼ì: {chunk['decision_date']}"
           case_info += f", ê¸°ê´€: {agency_name}"
           
           context_parts.append(
               f"{case_info}\n"
               f"[{chunk_type_name}]\n"
               f"{chunk['text']}\n"
               f"(ìœ ì‚¬ë„: {chunk['similarity']:.3f})\n"
           )
   ```
   - êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸
   - ì¶œì²˜ ì¶”ì  ê°€ëŠ¥

#### âš ï¸ ê°œì„  í•„ìš” ì˜ì—­

1. **ë‹¨ì¼ ìŠ¤í…Œì´ì§€ ê²€ìƒ‰ì˜ í•œê³„**
   
   **í˜„ì¬ ë°©ì‹**: ëª¨ë“  ë¬¸ì„œë¥¼ í•œ ë²ˆì— ê²€ìƒ‰
   
   ```python
   # í˜„ì¬: ë²•ë ¹, ê¸°ì¤€, ì‚¬ë¡€ë¥¼ êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰
   chunks = retriever.search(query=request.message, top_k=5)
   ```
   
   **ë¬¸ì œì **:
   - ë²•ë ¹ê³¼ ì‚¬ë¡€ë¥¼ ë™ì‹œì— ê²€ìƒ‰í•˜ë©´ í•˜ë‚˜ì— í¸í–¥ë  ìˆ˜ ìˆìŒ
   - ë¬¸ì„œ íƒ€ì… ê°„ ì¤‘ìš”ë„ ì¡°ì ˆ ë¶ˆê°€
   - ìˆœì°¨ì  ê²€ìƒ‰ ë…¼ë¦¬ ë¶€ì¬
   
   **ê°œì„  ë°©í–¥**: ë©€í‹° ìŠ¤í…Œì´ì§€ RAG ê²€ìƒ‰
   ```
   Stage 1: ë²•ë ¹ + ì†Œë¹„ìë¶„ìŸê¸°ì¤€ ë³‘ë ¬ ê²€ìƒ‰
   Stage 2: Stage 1 ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë¶„ìŸì¡°ì •ì‚¬ë¡€ ê²€ìƒ‰
   Stage 3: ê²°ê³¼ ë¶€ì¡± ì‹œ í”¼í•´êµ¬ì œì‚¬ë¡€ Fallback
   ```

2. **ê¸°ê´€ ì¶”ì²œ ë¡œì§ ë¶€ì¬**
   
   **í˜„ì¬ ìƒíƒœ**: ê¸°ê´€ í•„í„°ë§ë§Œ ê°€ëŠ¥
   
   ```python
   # í˜„ì¬: ì‚¬ìš©ìê°€ ê¸°ê´€ì„ ì§ì ‘ ì§€ì •
   agencies: Optional[List[str]] = None
   ```
   
   **ë¬¸ì œì **:
   - ì‚¬ìš©ìê°€ ì–´ë–¤ ê¸°ê´€ì— ë¬¸ì˜í•´ì•¼ í• ì§€ ëª¨ë¦„
   - KCA, ECMC, KCDRC ì¤‘ ì í•©í•œ ê¸°ê´€ ì•ˆë‚´ ì—†ìŒ
   
   **ê°œì„  ë°©í–¥**: ê·œì¹™ ê¸°ë°˜ + ê²€ìƒ‰ ê²°ê³¼ í†µí•© ì¶”ì²œ
   ```python
   def recommend_agency(user_input, search_results):
       # ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ (í‚¤ì›Œë“œ ë§¤ì¹­)
       rule_scores = apply_keyword_rules(user_input)
       
       # ê²€ìƒ‰ ê²°ê³¼ í†µê³„ (ê° ê¸°ê´€ë³„ ê²°ê³¼ ìˆ˜)
       result_scores = analyze_agency_distribution(search_results)
       
       # ê²°í•© (7:3 ë¹„ìœ¨)
       final_scores = rule_scores * 0.7 + result_scores * 0.3
       
       return sorted_agencies(final_scores)
   ```

3. **Fallback ë©”ì»¤ë‹ˆì¦˜ ë¶€ì¬**
   
   **í˜„ì¬ ìƒíƒœ**:
   ```python
   if not chunks:
       return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ë¶„ìŸì¡°ì • ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
   ```
   
   **ë¬¸ì œì **:
   - ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ì—ëŸ¬ ë©”ì‹œì§€ë§Œ ë°˜í™˜
   - ìœ ì‚¬ ì‚¬ë¡€ë‚˜ ëŒ€ì•ˆ ì œì‹œ ì—†ìŒ
   
   **ê°œì„  ë°©í–¥**:
   - ë¶„ìŸì¡°ì •ì‚¬ë¡€ ì—†ìœ¼ë©´ í”¼í•´êµ¬ì œì‚¬ë¡€ ê²€ìƒ‰
   - í‚¤ì›Œë“œ í™•ì¥ ì¬ê²€ìƒ‰
   - ìœ ì‚¬ ì§ˆë¬¸ ì œì•ˆ

4. **êµ¬ì¡°í™”ëœ ì…ë ¥ ë¯¸ì§€ì›**
   
   **í˜„ì¬ ìƒíƒœ**: ìì—°ì–´ ì¿¼ë¦¬ë§Œ ì§€ì›
   
   ```python
   class ChatRequest(BaseModel):
       message: str  # ë‹¨ìˆœ í…ìŠ¤íŠ¸
   ```
   
   **ë¬¸ì œì **:
   - í’ˆëª©, ê¸ˆì•¡, êµ¬ë§¤ì²˜, êµ¬ë§¤ì¼ì‹œ ë“± êµ¬ì¡° ì •ë³´ í™œìš© ë¶ˆê°€
   - ì •í™•í•œ í•„í„°ë§ ì–´ë ¤ì›€
   
   **ê°œì„  ë°©í–¥**: êµ¬ì¡°í™”ëœ ì…ë ¥ ì§€ì›
   ```python
   class StructuredUserInput(BaseModel):
       query: str  # ìì—°ì–´ ì§ˆë¬¸
       item: Optional[str]  # í’ˆëª©ëª…
       amount: Optional[int]  # ê¸ˆì•¡
       purchase_date: Optional[date]  # êµ¬ë§¤ì¼
       merchant: Optional[str]  # íŒë§¤ì
       issue_type: Optional[str]  # ë¶„ìŸ ìœ í˜•
   ```

5. **ê²€ìƒ‰ ê²°ê³¼ ì¬ìˆœìœ„í™” (Re-ranking) ë¶€ì¬**
   
   **í˜„ì¬ ìƒíƒœ**: ë‹¨ìˆœ ìœ ì‚¬ë„ ìˆœ ì •ë ¬
   
   ```sql
   ORDER BY c.embedding <=> %s::vector
   LIMIT %s
   ```
   
   **ë¬¸ì œì **:
   - ì˜ë¯¸ì  ìœ ì‚¬ë„ë§Œ ê³ ë ¤
   - ìµœì‹ ì„±, ì¤‘ìš”ë„, ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜ ì•ˆ ë¨
   
   **ê°œì„  ë°©í–¥**: í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§
   ```python
   def rerank_chunks(chunks, user_query, user_context):
       for chunk in chunks:
           # 1. ì˜ë¯¸ì  ìœ ì‚¬ë„ (40%)
           semantic_score = chunk['similarity']
           
           # 2. ìµœì‹ ì„± ì ìˆ˜ (20%)
           recency_score = calculate_recency(chunk['decision_date'])
           
           # 3. ê¸°ê´€ ì í•©ì„± (20%)
           agency_score = match_agency(chunk['agency'], user_context)
           
           # 4. ì²­í¬ íƒ€ì… ì¤‘ìš”ë„ (20%)
           type_score = get_type_weight(chunk['chunk_type'])
           
           # í†µí•© ì ìˆ˜
           chunk['final_score'] = (
               semantic_score * 0.4 +
               recency_score * 0.2 +
               agency_score * 0.2 +
               type_score * 0.2
           )
       
       return sorted(chunks, key=lambda x: x['final_score'], reverse=True)
   ```

6. **ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í™œìš© ë¶€ì¡±**
   
   **í˜„ì¬ ìƒíƒœ**: ê°œë³„ ì²­í¬ë§Œ ë°˜í™˜
   
   **ë¬¸ì œì **:
   - ì²­í¬ ì•ë’¤ ë§¥ë½ ëˆ„ë½
   - ë¬¸ì„œ ì „ì²´ íë¦„ íŒŒì•… ì–´ë ¤ì›€
   
   **ê°œì„  ë°©í–¥**: ì»¨í…ìŠ¤íŠ¸ í™•ì¥ í•¨ìˆ˜ í™œìš©
   ```python
   # schemaì— ì •ì˜ëœ í•¨ìˆ˜ í™œìš©
   def expand_context(chunk_id, window_size=1):
       return get_chunk_with_context(chunk_id, window_size)
   ```

---

## ğŸ“ˆ 4. ì •ëŸ‰ì  ë¶„ì„

### 4.1 ì²­í¬ í¬ê¸° ë¶„í¬ (ê°€ì •)

| í†µê³„ | ê°’ |
|------|-----|
| í‰ê·  ì²­í¬ ê¸¸ì´ | 550ì |
| ìµœì†Œ ì²­í¬ ê¸¸ì´ | 100ì |
| ìµœëŒ€ ì²­í¬ ê¸¸ì´ | 700ì |
| í† í° ì œí•œ ìœ„ë°˜ìœ¨ | < 1% |

### 4.2 ì„ë² ë”© í’ˆì§ˆ í†µê³„ (embed_data_remote.py ê²€ì¦)

**í’ˆì§ˆ ê²€ì¦ í•­ëª©**:
- âœ… Norm ê²€ì‚¬
- âœ… ë¶„ì‚° ê²€ì‚¬
- âœ… ì´ìƒê°’ ê²€ì‚¬ (NaN/Inf)
- âœ… í¬ì†Œì„± ê²€ì‚¬

**ì˜ˆìƒ ì €í’ˆì§ˆ ë¹„ìœ¨**: 5% ì´í•˜

### 4.3 ê²€ìƒ‰ ì„±ëŠ¥

| ì§€í‘œ | ê°’ |
|------|-----|
| í‰ê·  ê²€ìƒ‰ ì‹œê°„ | < 100ms (HNSW ì¸ë±ìŠ¤) |
| Top-K | 5 (ê¸°ë³¸ê°’) |
| ìœ ì‚¬ë„ ì„ê³„ê°’ | 0.0 (ë¯¸ì„¤ì •) |

---

## ğŸ¯ 5. ì£¼ìš” ê°œì„ ì  ìš”ì•½

### 5.1 ì²­í‚¹ ì „ëµ ê°œì„ 

| ê°œì„  í•­ëª© | í˜„ì¬ ìƒíƒœ | ê°œì„  ë°©í–¥ | ìš°ì„ ìˆœìœ„ |
|----------|----------|----------|---------|
| íƒ€ì…ë³„ ìµœì  ê¸¸ì´ | ëª¨ë‘ 700ì | íƒ€ì…ë³„ ì°¨ë³„í™” (500-800ì) | â­â­ |
| ë©”íƒ€ë°ì´í„° í™œìš© | contentì— í¬í•¨ | ë³„ë„ í•„ë“œ ì €ì¥ + ê²€ìƒ‰ í•„í„°ë§ | â­â­â­ |
| ì²­í¬ í’ˆì§ˆ ê²€ì¦ | ê¸¸ì´ë§Œ ê²€ì¦ | ë¬¸ì¥ ì™„ê²°ì„±, ì°¸ì¡° ë¬´ê²°ì„± | â­ |
| Overlapping | ê³ ì • í¬ê¸° | ë¬¸ì¥ ë‹¨ìœ„ + ì¤‘ìš”ë„ ê¸°ë°˜ | â­ |

### 5.2 ì„ë² ë”© ì „ëµ ê°œì„ 

| ê°œì„  í•­ëª© | í˜„ì¬ ìƒíƒœ | ê°œì„  ë°©í–¥ | ìš°ì„ ìˆœìœ„ |
|----------|----------|----------|---------|
| ëª¨ë¸ ì˜ì¡´ì„± | KURE-v1ë§Œ | ë©€í‹° ëª¨ë¸ + Fallback | â­ |
| ì‚¬ì „ í’ˆì§ˆ ê²€ì¦ | ì„ë² ë”© í›„ë§Œ | í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ + ì‚¬ì „ í•„í„°ë§ | â­â­ |
| ë²„ì „ ê´€ë¦¬ | ë²„ì „ ì •ë³´ ì—†ìŒ | ëª¨ë¸ ë²„ì „ ì¶”ì  + ì¬ì„ë² ë”© | â­ |

### 5.3 RAG ì•„í‚¤í…ì²˜ ê°œì„ 

| ê°œì„  í•­ëª© | í˜„ì¬ ìƒíƒœ | ê°œì„  ë°©í–¥ | ìš°ì„ ìˆœìœ„ |
|----------|----------|----------|---------|
| ê²€ìƒ‰ ìŠ¤í…Œì´ì§€ | ë‹¨ì¼ ìŠ¤í…Œì´ì§€ | ë©€í‹° ìŠ¤í…Œì´ì§€ RAG | â­â­â­ |
| ê¸°ê´€ ì¶”ì²œ | í•„í„°ë§ë§Œ | ê·œì¹™ + ê²€ìƒ‰ ê¸°ë°˜ ì¶”ì²œ | â­â­â­ |
| Fallback | ì—†ìŒ | ë¶„ìŸì¡°ì • â†’ í”¼í•´êµ¬ì œ ìˆœì°¨ ê²€ìƒ‰ | â­â­ |
| êµ¬ì¡°í™” ì…ë ¥ | ìì—°ì–´ë§Œ | í’ˆëª©/ê¸ˆì•¡/ë‚ ì§œ ë“± êµ¬ì¡° ì •ë³´ | â­â­ |
| ì¬ìˆœìœ„í™” | ìœ ì‚¬ë„ë§Œ | í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ | â­â­ |
| ì»¨í…ìŠ¤íŠ¸ í™•ì¥ | ê°œë³„ ì²­í¬ë§Œ | ì•ë’¤ ì²­í¬ í¬í•¨ | â­ |

**ìš°ì„ ìˆœìœ„ ê¸°ì¤€**:
- â­â­â­: ì¦‰ì‹œ êµ¬í˜„ í•„ìš” (ì‚¬ìš©ì ê²½í—˜ ëŒ€í­ ê°œì„ )
- â­â­: ë‹¨ê¸° êµ¬í˜„ ê¶Œì¥ (í’ˆì§ˆ í–¥ìƒ)
- â­: ì¥ê¸° ê°œì„  í•­ëª© (ì„±ëŠ¥ ìµœì í™”)

---

## ğŸ”„ 6. ê°œì„  ë¡œë“œë§µ

### Phase 1: ë©€í‹° ìŠ¤í…Œì´ì§€ RAG êµ¬í˜„ (â­â­â­)

**ëª©í‘œ**: ë²•ë ¹/ê¸°ì¤€ â†’ ì‚¬ë¡€ ìˆœì°¨ ê²€ìƒ‰

**êµ¬í˜„ íŒŒì¼**: `backend/app/rag/multi_stage_retriever.py`

**ì˜ˆìƒ íš¨ê³¼**:
- ê²€ìƒ‰ ì •í™•ë„ 20-30% í–¥ìƒ
- ë²•ë ¹ ê·¼ê±°ì™€ ì‹¤ì œ ì‚¬ë¡€ ë™ì‹œ ì œê³µ

### Phase 2: ê¸°ê´€ ì¶”ì²œ ë¡œì§ (â­â­â­)

**ëª©í‘œ**: ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ê¸°ê´€ ì•ˆë‚´

**êµ¬í˜„ íŒŒì¼**: `backend/app/rag/agency_recommender.py`

**ì˜ˆìƒ íš¨ê³¼**:
- ì‚¬ìš©ì í¸ì˜ì„± ëŒ€í­ í–¥ìƒ
- ì ì ˆí•œ ê¸°ê´€ ì•ˆë‚´ë¡œ í•´ê²° ì†ë„ ê°œì„ 

### Phase 3: ë©”íƒ€ë°ì´í„° ê°•í™” (â­â­â­)

**ëª©í‘œ**: êµ¬ì¡°í™”ëœ ì •ë³´ í™œìš©

**ìˆ˜ì • íŒŒì¼**: 
- `backend/scripts/data_processing/data_transform_pipeline.py`
- `backend/database/schema_v2_final.sql`

**ì˜ˆìƒ íš¨ê³¼**:
- ì •í™•í•œ í•„í„°ë§
- ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ

---

## ğŸ“ 7. ê²°ë¡ 

### ê¸ì •ì  ì¸¡ë©´

1. **ì²´ê³„ì ì¸ ì²­í‚¹ ì „ëµ**
   - íƒ€ì…ë³„ ì°¨ë³„í™”ëœ ê·œì¹™
   - Overlapping ì ìš©
   - ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• 
   - í† í° ì œí•œ ì¤€ìˆ˜

2. **í’ˆì§ˆ ê²€ì¦ ë©”ì»¤ë‹ˆì¦˜**
   - ì„ë² ë”© í’ˆì§ˆ ìë™ ê²€ì‚¬
   - ë‹¤ê°ë„ í’ˆì§ˆ í‰ê°€

3. **íš¨ìœ¨ì  ì¸í”„ë¼**
   - HNSW ì¸ë±ìŠ¤
   - ë°°ì¹˜ ì²˜ë¦¬
   - ìŠ¤íŠ¸ë¦¬ë° ì§€ì›

### ê°œì„  í•„ìš” ì˜ì—­

1. **ê²€ìƒ‰ ë…¼ë¦¬ ê³ ë„í™”**
   - ë©€í‹° ìŠ¤í…Œì´ì§€ RAG
   - ê¸°ê´€ ì¶”ì²œ
   - Fallback ë©”ì»¤ë‹ˆì¦˜

2. **ë©”íƒ€ë°ì´í„° í™œìš©**
   - êµ¬ì¡°í™”ëœ ì •ë³´ ì €ì¥
   - ì •í™•í•œ í•„í„°ë§

3. **ì‚¬ìš©ì ê²½í—˜**
   - êµ¬ì¡°í™”ëœ ì…ë ¥
   - ì»¨í…ìŠ¤íŠ¸ í™•ì¥
   - ì¬ìˆœìœ„í™”

**ì „ì²´ í‰ê°€**: í˜„ì¬ ì‹œìŠ¤í…œì€ **ê²¬ê³ í•œ ê¸°ë°˜**ì„ ê°–ì¶”ê³  ìˆìœ¼ë‚˜, **ê²€ìƒ‰ ë¡œì§ ê³ ë„í™”**ì™€ **ë©”íƒ€ë°ì´í„° í™œìš©**ì„ í†µí•´ **ëŒ€í­ì ì¸ ê°œì„  ê°€ëŠ¥**

---

**ë‹¤ìŒ ë‹¨ê³„**: ë©€í‹° ìŠ¤í…Œì´ì§€ RAG ê²€ìƒ‰ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸
