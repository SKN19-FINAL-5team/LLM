#     

****: 2026-01-06  
****: RAG            

---

##  

RAG           :

1. **  **:       
2. ** **: , ,     

---

##    

### 

   :
- **92 Critical Issues**:  content 
- **~1,500  ** (~10 ): " ", ". " 
- **~300  ** (~10,000 ): judgment  

  RAG     .

###  

#### 1.     

```python
CHUNK_PROCESSING_RULES = {
    'decision': {
        'min_length': 50,
        'max_length': 800,
        'merge_allowed': False,  #   
        'split_allowed': False,
        'drop_if_empty': True
    },
    'reasoning': {
        'min_length': 100,
        'max_length': 1500,
        'merge_allowed': True,
        'split_allowed': True
    },
    'judgment': {
        'min_length': 200,
        'max_length': 1500,
        'merge_allowed': True,
        'split_allowed': True,  #    
    },
    'law': {
        'min_length': 30,
        'max_length': 2000,
        'merge_allowed': False,
        'split_allowed': False,
        'drop_if_empty': True,
        'enrich_with_metadata': True
    },
    # ...  
}
```

#### 2.    

****: `_merge_short_chunks(chunks: List[Dict]) -> List[Dict]`

** **:
-      
-    `merge_allowed=True`   
-   ,   
- `drop=True`    

****:
```python
#  
[
    {'content': ' ', 'chunk_type': 'reasoning'},  # 3 ( )
    {'content': ' ...', 'chunk_type': 'reasoning'}  # 100 
]

#  
[
    {'content': ' \n\n ...', 'chunk_type': 'reasoning'}
]
```

#### 3.    

****: `_split_long_chunks(chunks: List[Dict]) -> List[Dict]`

** **:
-      
-    `split_allowed=True`    
- (`\n\n+`)      
-   ID `{_chunk_id}_sub{}` 

****:
```python
#  
{
    'chunk_id': 'kca:mediation:001:judgment:0000',
    'content': '  ...\n\n ...\n\n ...',  # 3000
    'chunk_type': 'judgment'
}

#  
[
    {
        'chunk_id': 'kca:mediation:001:judgment:0000',
        'content': '  ...',  # ~1500
        'chunk_type': 'judgment'
    },
    {
        'chunk_id': 'kca:mediation:001:judgment:0000_sub1',
        'content': ' ...\n\n ...',  # ~1500
        'chunk_type': 'judgment'
    }
]
```

#### 4.   

****: `_optimize_chunks(chunks: List[Dict]) -> List[Dict]`

** **:
1.    (`_merge_short_chunks`)
2.    (`_split_long_chunks`)
3.    (`drop_if_empty=True`  `drop=True` )

** **:
- `transform_law_data()`:    
- `transform_criteria_table2()`:    
- `transform_mediation_kca()`: KCA   
- `transform_mediation_ecmc()`: ECMC   
- `transform_counsel_case()`:   

###  

|  |   |   |  |
|------|---------|---------|--------|
| Critical Issues ( ) | 92 | 0 |  100% |
|   (< 100) | ~1,500 | 310 |  80%  |
|    (100-2000) | - | 13,530 (95.6%) |   |
|    | 14,898 | 14,337 |  561  |

---

##   

### 

Hybrid Search(  +  )        :

- ****: TF-IDF   
- ****: ,  
- ** **:    
- ** **: ,   
- ** **:   
- ****:    

###  

#### 1. MetadataEnricher 

****: `backend/scripts/data_processing/metadata_enricher.py`

** **:

```python
class MetadataEnricher:
    def extract_keywords(self, content: str, top_k: int = 10) -> List[str]:
        """TF-IDF   """
    
    def extract_entities(self, content: str) -> Dict[str, List[str]]:
        """,    """
    
    def extract_legal_terms(self, content: str) -> List[str]:
        """  """
    
    def infer_category(self, content: str) -> List[str]:
        """  """
    
    def extract_law_references(self, content: str) -> List[str]:
        """  """
    
    def extract_dates(self, content: str) -> List[str]:
        """  """
    
    def enrich_chunk_metadata(self, chunk: Dict, extract_all: bool = True) -> Dict:
        """  """
```

#### 2.    

****: `backend/scripts/data_processing/data_transform_pipeline.py`

** **:

```python
class DataTransformer:
    def __init__(self, output_dir: Path = None, use_db: bool = False, 
                 enrich_metadata: bool = True):
        """
        Args:
            enrich_metadata:   
        """
        self.enrich_metadata = enrich_metadata
        if enrich_metadata:
            self.metadata_enricher = MetadataEnricher()
            print("   ")
        else:
            self.metadata_enricher = None
    
    def _enrich_document(self, doc_data: Dict) -> Dict:
        """     """
        if not self.enrich_metadata or not self.metadata_enricher:
            return doc_data
        
        enriched_count = 0
        for chunk in doc_data.get('chunks', []):
            # drop=True  
            if chunk.get('drop', False):
                continue
            
            #  
            self.metadata_enricher.enrich_chunk_metadata(chunk, extract_all=True)
            enriched_count += 1
        
        self.stats['enriched_chunks'] += enriched_count
        return doc_data
```

** **:
-       `_enrich_document()` 
- `transform_law_data()`, `transform_criteria_table2()`, `transform_mediation_kca()`, `transform_mediation_ecmc()`, `transform_counsel_case()`

#### 3.  

   :

```json
{
  "chunk_id": "kca:mediation:001:judgment:0000",
  "chunk_type": "judgment",
  "content": " ...",
  "metadata": {
    "keywords": ["", "", "", ""],
    "entities": {
      "companies": [" "],
      "products": [" S24"]
    },
    "legal_terms": ["", "", "", ""],
    "category_tags": ["", "", ""],
    "law_references": [" 750", " 16"],
    "dates": ["2024-01-15", "2024.01.20"]
  }
}
```

###  

####    ()

```python
#    
transformer = DataTransformer(enrich_metadata=True)
transformer.run_transformation()
```

####   

```python
#   
transformer = DataTransformer(enrich_metadata=False)
transformer.run_transformation()
```

###  

       :

```
================================================================================
  
================================================================================
  -  : 11,976
  -  : 14,337
  - : 0
  -  : 14,027 
  - : 0
```

---

##   

###     

```
1.    (JSONL)
   ↓
2.      
   ↓
3.  
      
      
      
   ↓
4. chunk_index  (0-based)
   ↓
5.  
     
     
      
     
      
     
   ↓
6. 
   ↓
7. JSON 
```

###  

```bash
#    (  +   )
cd /home/maroco/ddoksori_demo
conda activate ddoksori
python backend/scripts/data_processing/data_transform_pipeline.py

#  :
#    
# ================================================================================
#   
# ================================================================================
# ...
#    : 792  ( )
# ...
# ================================================================================
#   
# ================================================================================
#   -  : 11,976
#   -  : 14,337
#   -  : 14,027 
#   - : 0
```

---

##   

###   

```bash
python backend/scripts/data_processing/validate_transformed_data.py
```

###   

```
================================================================================
 
================================================================================

  :
  -  : 11,976
  -  : 14,337

 RAG   (100-2000 ):
  -  : 13,530 (95.6%)
  -  : 310 (2.2%)
  -  : 319 (2.3%)

 :
  -  Critical : 0
  -   : 1,028

================================================================================
  !   .
   (    )
================================================================================
```

---

##  Hybrid Search 

     Hybrid Search :

###  

```sql
--   +  
SELECT 
    c.chunk_id,
    c.content,
    d.title,
    1 - (c.embedding <=> query_embedding) as similarity
FROM chunks c
JOIN documents d ON c.doc_id = d.doc_id
WHERE 
    --   
    c.embedding <=> query_embedding < 0.3
    --  
    AND d.doc_type = 'mediation_case'
    AND d.source_org = 'KCA'
    AND c.metadata->>'category_tags' @> '[""]'::jsonb
    AND c.metadata->>'keywords' @> '["", ""]'::jsonb
    AND c.drop = FALSE
ORDER BY c.embedding <=> query_embedding
LIMIT 10;
```

###  

- ****: `metadata->>'category_tags'`
- ****: `metadata->>'keywords'`
- ** **: `metadata->>'legal_terms'`
- ****: `metadata->>'entities'`
- ** **: `metadata->>'law_references'`
- ****: `metadata->>'dates'`

---

##    

###    

`backend/scripts/data_processing/data_transform_pipeline.py` `CHUNK_PROCESSING_RULES`     /   /    .

###   

`backend/scripts/data_processing/metadata_enricher.py`     :

- **  **: `self.legal_terms` 
- **  **: `self.category_keywords` 
- **  **: `extract_entities()`   

---

##  

###  

1. **  **:   10-50ms  (   )
2. **  **: 14,000    5-10  
3. ** **:    JSON    10-20% 

### 

1. **  **: `merge_allowed=False`   
2. **  **: `split_allowed=False`   
3. ** **:   (< 20)       

---

##   

- [    ](./____.md)
- [   ](./___.md)
- [RAG    ](../.cursor/plans/____22a4ef1e.plan.md)

---

##   

###  

- `backend/scripts/data_processing/data_transform_pipeline.py`:    (  )
- `backend/scripts/data_processing/metadata_enricher.py`:   
- `backend/scripts/data_processing/validate_transformed_data.py`:   (  )

###  

- `DataTransformer._optimize_chunks()`:    
- `DataTransformer._merge_short_chunks()`:   
- `DataTransformer._split_long_chunks()`:   
- `DataTransformer._enrich_document()`:   
- `MetadataEnricher.enrich_chunk_metadata()`:   

---

****: Manus AI  
** **: 2026-01-06
