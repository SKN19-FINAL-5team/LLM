"""
Naver SPLADE ëª¨ë¸ ì ìš© ìŠ¤ë‹ˆí«
HuggingFace: naver/splade-v3
HuggingFace ê¶Œì¥ ë°©ì‹: SparseEncoder ì‚¬ìš©
"""

import torch
from typing import List, Dict, Optional
import numpy as np
import psycopg2
import os
from dotenv import load_dotenv
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
backend_dir = Path(__file__).parent.parent
env_file = backend_dir / '.env'
if env_file.exists():
    load_dotenv(env_file)
else:
    root_env = Path(__file__).parent.parent.parent / '.env'
    if root_env.exists():
        load_dotenv(root_env)
    else:
        load_dotenv()

# HuggingFace í† í° í™•ì¸
HF_TOKEN = os.getenv('HF_TOKEN') or os.getenv('HUGGINGFACE_TOKEN')


class NaverSPLADERetriever:
    """Naver SPLADE ëª¨ë¸ ê¸°ë°˜ Retriever (SparseEncoder ì‚¬ìš©)"""
    
    def __init__(self, model_name: str = "naver/splade-v3", device: str = None):
        """
        Args:
            model_name: Naver SPLADE ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: naver/splade-v3)
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu', Noneì´ë©´ ìë™ ì„ íƒ)
                    'cuda'ë¡œ ëª…ì‹œí•˜ë©´ GPU ì‚¬ìš©, Noneì´ë©´ ìë™ ê°ì§€
        """
        self.model_name = model_name
        self.model = None
        # device ëª…ì‹œì  ì§€ì • ë˜ëŠ” ìë™ ê°ì§€
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
        self.use_sparse_encoder = True
        print(f"ğŸ”§ SPLADE Retriever ì´ˆê¸°í™”: device={self.device}, CUDA available={torch.cuda.is_available()}")
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ (SparseEncoder ìš°ì„ , ì‹¤íŒ¨ ì‹œ SentenceTransformer ì‹œë„)"""
        if self.model is None:
            print(f"Loading SPLADE model: {self.model_name}")
            print(f"Device: {self.device}")
            
            # safetensors ì‚¬ìš© ê°•ì œ (torch ë²„ì „ ë¬¸ì œ íšŒí”¼)
            os.environ['SAFETENSORS_FAST_GPU'] = '1'
            # transformersì—ì„œ safetensors ìš°ì„  ì‚¬ìš©
            os.environ['TRANSFORMERS_SAFE_LOADING'] = '1'
            
            # SparseEncoder ì‹œë„ (HuggingFace ê¶Œì¥)
            try:
                from sentence_transformers import SparseEncoder
                print("  ì‹œë„: SparseEncoder (safetensors ìš°ì„ )...")
                self.model = SparseEncoder(
                    self.model_name,
                    token=HF_TOKEN if HF_TOKEN else None,
                    trust_remote_code=True
                )
                self.use_sparse_encoder = True
                print("âœ… SparseEncoderë¡œ ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
                return
            except ImportError:
                print("  âš ï¸  SparseEncoderë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (sentence-transformers ë²„ì „ í™•ì¸ í•„ìš”)")
            except Exception as e:
                error_str = str(e)
                print(f"  âš ï¸  SparseEncoder ë¡œë“œ ì‹¤íŒ¨: {error_str}")
                
                # torch ë²„ì „ ë¬¸ì œì¸ ê²½ìš°
                if "torch.load" in error_str or "CVE-2025-32434" in error_str or "torch>=2.6" in error_str:
                    print("  ğŸ’¡ torch ë²„ì „ ë¬¸ì œ ê°ì§€ (í˜„ì¬: 2.5.1, í•„ìš”: 2.6+)")
                    print("  ğŸ’¡ í•´ê²° ë°©ë²•:")
                    print("     1. torch ì—…ê·¸ë ˆì´ë“œ: pip install torch>=2.6")
                    print("     2. ë˜ëŠ” ëª¨ë¸ì´ safetensors í˜•ì‹ìœ¼ë¡œ ì œê³µë˜ëŠ”ì§€ í™•ì¸")
                    print("  âš ï¸  í˜„ì¬ëŠ” SPLADE ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    raise RuntimeError("torch ë²„ì „ì´ 2.6 ë¯¸ë§Œì…ë‹ˆë‹¤. torch>=2.6ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ê±°ë‚˜ safetensors í˜•ì‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            
            # SentenceTransformer ëŒ€ì•ˆ ì‹œë„ (í•˜ì§€ë§Œ SPLADEëŠ” sparse vectorë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ)
            print("  âš ï¸  SentenceTransformerëŠ” SPLADE sparse vectorë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            raise RuntimeError("SPLADE ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. SparseEncoderê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    def encode_query(self, query: str):
        """
        ì¿¼ë¦¬ë¥¼ Sparse Vectorë¡œ ì¸ì½”ë”©
        
        Args:
            query: ì…ë ¥ ì¿¼ë¦¬
        
        Returns:
            Sparse vector (torch tensor ë˜ëŠ” numpy array, 30522ì°¨ì›)
        """
        self.load_model()
        
        if self.use_sparse_encoder:
            # SparseEncoder ì‚¬ìš©
            query_emb = self.model.encode_query([query])
            # torch tensorì¸ ê²½ìš° ì²˜ë¦¬
            import torch
            if isinstance(query_emb, torch.Tensor):
                # sparse tensorì¸ ê²½ìš° denseë¡œ ë³€í™˜
                if query_emb.is_sparse:
                    query_emb = query_emb.to_dense()
                # numpyë¡œ ë³€í™˜
                query_emb = query_emb.cpu().numpy()
            # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜ (ë°°ì¹˜ê°€ 1ê°œì´ë¯€ë¡œ)
            if len(query_emb.shape) > 1:
                return query_emb[0]
            return query_emb
        else:
            # SentenceTransformer ì‚¬ìš© (ì¼ë°˜ ì„ë² ë”©)
            # SPLADEëŠ” sparse vectorë¥¼ ë°˜í™˜í•´ì•¼ í•˜ë¯€ë¡œ ì´ ê²½ìš°ëŠ” ì§€ì›í•˜ì§€ ì•ŠìŒ
            raise NotImplementedError("SentenceTransformerëŠ” SPLADE sparse vectorë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. SparseEncoderë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    
    def encode_document(self, document: str):
        """
        ë¬¸ì„œë¥¼ Sparse Vectorë¡œ ì¸ì½”ë”©
        
        Args:
            document: ì…ë ¥ ë¬¸ì„œ
        
        Returns:
            Sparse vector (torch tensor ë˜ëŠ” numpy array, 30522ì°¨ì›)
        """
        self.load_model()
        
        if self.use_sparse_encoder:
            # SparseEncoder ì‚¬ìš©
            doc_emb = self.model.encode_document([document])
            # torch tensorì¸ ê²½ìš° ì²˜ë¦¬
            import torch
            if isinstance(doc_emb, torch.Tensor):
                # sparse tensorì¸ ê²½ìš° denseë¡œ ë³€í™˜
                if doc_emb.is_sparse:
                    doc_emb = doc_emb.to_dense()
                # numpyë¡œ ë³€í™˜
                doc_emb = doc_emb.cpu().numpy()
            # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
            if len(doc_emb.shape) > 1:
                return doc_emb[0]
            return doc_emb
        else:
            raise NotImplementedError("SentenceTransformerëŠ” SPLADE sparse vectorë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def compute_similarity(
        self,
        query_vec,
        doc_vec
    ) -> float:
        """
        ì¿¼ë¦¬ì™€ ë¬¸ì„œ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (dot product)
        
        Args:
            query_vec: ì¿¼ë¦¬ sparse vector (torch tensor ë˜ëŠ” numpy array)
            doc_vec: ë¬¸ì„œ sparse vector (torch tensor ë˜ëŠ” numpy array)
        
        Returns:
            ìœ ì‚¬ë„ ì ìˆ˜
        """
        # torch tensorì¸ ê²½ìš° numpyë¡œ ë³€í™˜
        import torch
        if isinstance(query_vec, torch.Tensor):
            if query_vec.is_sparse:
                query_vec = query_vec.to_dense()
            query_vec = query_vec.cpu().numpy()
        if isinstance(doc_vec, torch.Tensor):
            if doc_vec.is_sparse:
                doc_vec = doc_vec.to_dense()
            doc_vec = doc_vec.cpu().numpy()
        
        # Sparse vectorì˜ dot product
        similarity = np.dot(query_vec, doc_vec)
        return float(similarity)
    
    def search(
        self,
        query: str,
        documents: List[str],
        top_k: int = 10
    ) -> List[tuple]:
        """
        ê²€ìƒ‰ ìˆ˜í–‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            documents: ê²€ìƒ‰ ëŒ€ìƒ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
        
        Returns:
            (ë¬¸ì„œ, ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        query_vec = self.encode_query(query)
        
        # ë¬¸ì„œë³„ ì ìˆ˜ ê³„ì‚°
        scores = []
        for doc in documents:
            doc_vec = self.encode_document(doc)
            score = self.compute_similarity(query_vec, doc_vec)
            scores.append((doc, score))
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        scores.sort(key=lambda x: x[1], reverse=True)
        
        return scores[:top_k]


class NaverSPLADEDBRetriever:
    """Naver SPLADE ëª¨ë¸ì„ ì‚¬ìš©í•œ DB ê²€ìƒ‰"""
    
    def __init__(
        self,
        db_config: Dict,
        model_name: str = "naver/splade-v3",
        device: str = None
    ):
        """
        Args:
            db_config: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
            model_name: SPLADE ëª¨ë¸ ì´ë¦„
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu', Noneì´ë©´ ìë™ ì„ íƒ)
        """
        self.db_config = db_config
        # deviceê°€ Noneì´ë©´ ìë™ ê°ì§€, 'cuda'ë¡œ ëª…ì‹œí•˜ë©´ GPU ê°•ì œ ì‚¬ìš©
        if device is None:
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.splade_retriever = NaverSPLADERetriever(model_name, device=device)
        self.conn = None
        print(f"ğŸ”§ SPLADE DB Retriever ì´ˆê¸°í™”: device={device}")
    
    def connect_db(self):
        """DB ì—°ê²°"""
        if self.conn is None or self.conn.closed:
            self.conn = psycopg2.connect(**self.db_config)
    
    def search_law_splade(
        self,
        query: str,
        top_k: int = 10
    ) -> List[Dict]:
        """ë²•ë ¹ SPLADE ê²€ìƒ‰"""
        self.connect_db()
        
        try:
            # ì¿¼ë¦¬ ì¸ì½”ë”©
            query_vec = self.splade_retriever.encode_query(query)
            
            if query_vec is None or query_vec.size == 0:
                return []
        except Exception as e:
            print(f"  âš ï¸  ì¿¼ë¦¬ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return []
        
        # ëª¨ë“  ë²•ë ¹ chunk ê°€ì ¸ì˜¤ê¸°
        cur = self.conn.cursor()
        cur.execute("""
            SELECT 
                c.chunk_id,
                c.doc_id,
                c.content,
                d.metadata->>'law_name' as law_name
            FROM chunks c
            JOIN documents d ON c.doc_id = d.doc_id
            WHERE d.doc_type = 'law'
            LIMIT 1000
        """)
        
        chunks = cur.fetchall()
        
        # ê° chunkì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
        results = []
        for chunk_id, doc_id, content, law_name in chunks:
            try:
                doc_vec = self.splade_retriever.encode_document(content)
                score = self.splade_retriever.compute_similarity(query_vec, doc_vec)
                
                if score > 0:
                    results.append({
                        'chunk_id': chunk_id,
                        'doc_id': doc_id,
                        'content': content,
                        'law_name': law_name,
                        'splade_score': float(score)
                    })
            except Exception as e:
                # ê°œë³„ ë¬¸ì„œ ì¸ì½”ë”© ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì†
                continue
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        results.sort(key=lambda x: x['splade_score'], reverse=True)
        
        return results[:top_k]
    
    def search_criteria_splade(
        self,
        query: str,
        top_k: int = 10
    ) -> List[Dict]:
        """ê¸°ì¤€ SPLADE ê²€ìƒ‰"""
        self.connect_db()
        
        try:
            # ì¿¼ë¦¬ ì¸ì½”ë”©
            query_vec = self.splade_retriever.encode_query(query)
            
            if query_vec is None or query_vec.size == 0:
                return []
        except Exception as e:
            print(f"  âš ï¸  ì¿¼ë¦¬ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return []
        
        # ëª¨ë“  ê¸°ì¤€ chunk ê°€ì ¸ì˜¤ê¸°
        cur = self.conn.cursor()
        cur.execute("""
            SELECT 
                c.chunk_id,
                c.doc_id,
                c.content,
                d.metadata->>'item' as item
            FROM chunks c
            JOIN documents d ON c.doc_id = d.doc_id
            WHERE d.doc_type LIKE 'criteria%%'
            LIMIT 1000
        """)
        
        chunks = cur.fetchall()
        
        # ê° chunkì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
        results = []
        for chunk_id, doc_id, content, item in chunks:
            try:
                doc_vec = self.splade_retriever.encode_document(content)
                score = self.splade_retriever.compute_similarity(query_vec, doc_vec)
                
                if score > 0:
                    results.append({
                        'chunk_id': chunk_id,
                        'doc_id': doc_id,
                        'content': content,
                        'item': item,
                        'splade_score': float(score)
                    })
            except Exception as e:
                # ê°œë³„ ë¬¸ì„œ ì¸ì½”ë”© ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì†
                continue
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        results.sort(key=lambda x: x['splade_score'], reverse=True)
        
        return results[:top_k]


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    print("=== Naver SPLADE ëª¨ë¸ í…ŒìŠ¤íŠ¸ ===")
    retriever = NaverSPLADERetriever()
    
    query = "ë¯¼ë²• ì œ750ì¡° ë¶ˆë²•í–‰ìœ„"
    print(f"\nQuery: {query}")
    print("Encoding query...")
    
    try:
        query_vec = retriever.encode_query(query)
        print(f"âœ… Encoded sparse vector (shape: {query_vec.shape})")
        
        # numpy arrayë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
        import torch
        if isinstance(query_vec, torch.Tensor):
            if query_vec.is_sparse:
                query_vec = query_vec.to_dense()
            query_vec = query_vec.cpu().numpy()
        
        # 0ì´ ì•„ë‹Œ ê°’ì˜ ê°œìˆ˜
        non_zero_count = np.count_nonzero(query_vec)
        print(f"  Non-zero values: {non_zero_count}")
        
        # Top-10 ê°€ì¤‘ì¹˜
        top_indices = np.argsort(query_vec)[-10:][::-1]
        print("\nTop 10 token indices (ê°€ì¤‘ì¹˜):")
        for idx in top_indices:
            if query_vec[idx] > 0:
                print(f"  Token {idx}: {query_vec[idx]:.4f}")
        
        # ë¬¸ì„œ ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
        test_doc = "ë¯¼ë²• ì œ750ì¡° ë¶ˆë²•í–‰ìœ„ë¡œ ì¸í•œ ì†í•´ë°°ìƒ"
        print(f"\nDocument: {test_doc}")
        doc_vec = retriever.encode_document(test_doc)
        similarity = retriever.compute_similarity(query_vec, doc_vec)
        print(f"âœ… Similarity: {similarity:.4f}")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        print("\nNote: ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:")
        print("  1. HuggingFace ê³„ì • ë¡œê·¸ì¸ ë° ì ‘ê·¼ ê¶Œí•œ ìŠ¹ì¸")
        print("  2. sentence-transformers ì„¤ì¹˜: pip install sentence-transformers")
        print("  3. HF_TOKEN í™˜ê²½ ë³€ìˆ˜ ì„¤ì •")
